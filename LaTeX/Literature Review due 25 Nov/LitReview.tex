% -------------------------------------------------------------------------------
% Establish page structure & font.
\documentclass[12pt]{report}

\usepackage[total={6.5in, 9in},
	left=1in,
	right=1in,
	top=1in,
	bottom=1in,]{geometry} % Page structure

\usepackage{graphicx} % Required for inserting images
\graphicspath{{../.images/}} % Any additional images I use (BCU logo, etc) are from here.

\usepackage[utf8]{inputenc} % UTF-8 encoding
\usepackage[T1]{fontenc} % T1 font
\usepackage{float}  % Allows for floats to be positioned using [H], which correctly
                    % positions them relative to their location within my LaTeX code.
\usepackage{subcaption}
% \usepackage[british]{babel}
\usepackage{csquotes}

\usepackage{pdflscape} % Enables the page to be rotated 
                       % landscape for easier image viewing.

% -------------------------------------------------------------------------------
% Declare biblatex with custom Harvard BCU styling for referencing.
\usepackage[
    useprefix=true,
    maxcitenames=3,
    maxbibnames=99,
    style=authoryear,
    dashed=false, 
    natbib=true,
    url=false,
    backend=biber
]{biblatex}

% Additional styling options to ensure Harvard referencing format.
\renewbibmacro*{volume+number+eid}{
    \printfield{volume}
    \setunit*{\addnbspace}
    \printfield{number}
    \setunit{\addcomma\space}
    \printfield{eid}}
\DeclareFieldFormat[article]{number}{\mkbibparens{#1}}

% Declare it as the bibliography source, to be called later via \printbibliography
\addbibresource{litReview.bib}

% -------------------------------------------------------------------------------
% To prevent "Chapter N" display for each chapter
\usepackage[compact]{titlesec}
\usepackage{wasysym}
\usepackage{import}

\titlespacing*{\chapter}{0pt}{-2cm}{0.5cm}
\titleformat{\chapter}[display]
{\normalfont\bfseries}{}{0pt}{\Huge}

% -------------------------------------------------------------------------------
% Custom macro to make an un-numbered footnote.

\newcommand\blfootnote[1]{
    \begingroup
    \renewcommand\thefootnote{}\footnote{#1}
    \addtocounter{footnote}{-1}
    \endgroup
}

% -------------------------------------------------------------------------------
% Fancy headers; used to show my name, BCU logo and current chapter for the page.
\usepackage{fancyhdr}
\usepackage{calc}
\pagestyle{fancy}

\setlength\headheight{37pt} % Set custom header height to fit the image.

\renewcommand{\chaptermark}[1]{%
    \markboth{#1}{}} % Include chapter name.


% Lewis Higgins - ID 22133848           [BCU LOGO]                [CHAPTER NAME]
\lhead{Lewis Higgins - ID 22133848~~~~~~~~~~~~~~~\includegraphics[width=1.75cm]{BCU}}
\fancyhead[R]{\leftmark}

% ------------------------------------------------------------------------------
% Used to add PDF hyperlinks for figures and the contents page.

\usepackage{hyperref}

\hypersetup{
    colorlinks=true,
    linkcolor=black,
    filecolor=magenta,
    urlcolor=blue,
    citecolor=black,
}

% ------------------------------------------------------------------------------
\usepackage{xcolor} 
\usepackage{colortbl}
\usepackage{longtable}
\usepackage{amssymb}
% ------------------------------------------------------------------------------

% ------------------REMOVE ME --------------------------------------------------

% Temp, using to add notes for the draft edition.
\usepackage{tcolorbox}

% ----------------- REMOVE ME --------------------------------------------------

\begin{document}

    \makeatletter
    \begin{titlepage}
        \includegraphics[width=0.3\linewidth]{BCUWide.jpg}\\[4ex]
        \vspace{1cm}
        \begin{center}
            {\huge \bfseries  CMP6200}\\[2ex]
            {\huge \bfseries  Individual Undergraduate Project}\\[2ex]
            {\huge \bfseries 2024 - 2025}\\[6ex]
            {\large \bfseries A2 - Literature Review and Methods}\\[10ex]
            {\huge \bfseries University Artifically Intelligent Assistant}\\[6ex]
            \includegraphics[width=0.1\linewidth]{Symbol.png}\\[40ex]
            Course: Computer \& Data Science\\
            Student Name: Lewis Higgins\\
            Student Number: 22133848\\
            Supervisor Name: Dr. Atif Azad
        \end{center}
    \end{titlepage}
    \makeatother
    \thispagestyle{empty}
    \newpage

    \tableofcontents
    %\footnotesize{\listoffigures}

    \chapter{Report Introduction}\label{ch:introduction}
    \section{Aims and Objectives}

    \noindent
    This project aims to aid new and existing students alike while they are attending university with 
    helpful information about the university itself, such as university societies, locations/campuses, 
    and policies through the medium of a digital chatbot companion to converse with.
    Its objectives are to:

    \begin{itemize}
        \item Develop a chatbot capable of accurately answering user queries related to university 
        buildings, policies, and societies with a minimum 95\% accuracy rate.
        \item Conduct a thorough literature review on the surrounding topics, namely AI, LLMs and NLP.
        \item Create effective documentation for all stages of development, highlighting challenges faced during the process.
        \item Manage time effectively to ensure all project milestones are met on a consistent and regular timeframe.
        \item Evaluate the effectiveness of an AI assistant on university student acclimatization.
    \end{itemize}

    \pagebreak % REMOVE ME IF UNNECESSARY

    \section{Literature Search Methodology}

    \noindent 
    My literature search will be performed using multiple reputable databases for academic papers, including:
    \begin{itemize}
        \item IEEE Xplore
        \item Scopus / Elsevier
        \item Google Scholar
        \item BCU Online Library
    \end{itemize}
    
    \noindent By using multiple different databases to source my information from, I can ensure that
    any potentially relevant literature will be found. Figure \ref{fig:litSearch} depicts 
    how in a search for 1685 articles about employee retention strategies and turnover, only 582 (25.7\%) appeared in multiple databases
    \autocite{litSearch}, meaning that the remaining 74.3\% of articles were exclusive to the single 
    database in which they were found, emphasising the importance of searching multiple databases.  

    \begin{figure}[H]
        \centering
        \includegraphics[width=.5\linewidth]{litSearchDBs.jpg}
        \caption{Distribution of searched articles across databases. \autocite{litSearch}}
        \label{fig:litSearch}
    \end{figure}
   
    \noindent 
    All searches performed for recent literature will have a heavy preference 
    to more recent literature, due to the constantly evolving fields my project is based on. 
    The search terms I will use to retrieve the data I will be studying are:

    \begin{itemize}
        \item Artifical Intelligence / AI 
        \item Natural Language Processing / NLP
        \item Large Language Models / LLMs
        \item Chatbots / Conversational Agents
        % \item Human-Computer Interaction
        % \item Knowledge Bases
        % \item Deep learning
        \item User Experience / UX
        % \item Information retrieval
    \end{itemize}

    \noindent
    By using these specific terms that are directly relevant to the core themes of my project,
    I will be ensuring that I only retrieve literature that will be of crucial use in its 
    development.


    \chapter{Literature Review}

    \section{Themes}

    To develop the artefact and conduct thorough background research on relevant literature to further my 
    knowledge of the subject areas, key general themes of the project were identified. From these themes, further 
    keywords to be used in the literature search were derived to ensure that retrieved literature is directly relevant 
    to my research and development of the final artefact. Due to the constantly evolving fields the project focuses 
    on, it will be necessary to limit the results to only those written in recent years (2018 earliest) as there are 
    frequent new developments in the subject areas.

    % \begin{tcolorbox}[colback=red!5!white,colframe=red!75!black,title=Significant uncertainty]
    %     I had a large amount of difficulty identifying my project's key themes, as many of them overlap and I was
    %     unsure which would simply be keywords of others, which is most evident with "AI" and "Generative AI" seen below.
    %     From what I can gather so far, I'm not sure if just making a chatbot that just accesses another LLM's API is worthy 
    %     of being a dissertation project at all, and if it would be better to try with my own fine-tuned model of something 
    %     like LLaMA. I'd have much more to write about that way.
    % \end{tcolorbox}
\pagebreak
    \begin{table}[H]
        \centering
        \begin{tabular}{|p{0.2\textwidth}|p{0.52\textwidth} | p{0.23\textwidth}|}
            \hline
            \cellcolor{blue!25}Theme & \cellcolor{blue!25}Description &
            \cellcolor{blue!25}Keywords \\

            \hline

            AI & A field of computing dedicated to allowing computers to simulate human
            learning by training them on large amounts of data so that they can recognise patterns to classify or 
            predict unknown data. AI can only be as good as the data it is trained upon, and can 
            develop biases if it is fed too much data of a certain type. & Generative AI, 
            Human-Centred AI, Explaianble AI, AI Ethics, AI Bias \\

            % \hline

            % Generative AI & AI dedicated to the generation of content rather than prediction or 
            % classification. It is possible for generative AI to produce text, images and 
            % more recently, even video and sound. & LLMs, Tokens, Embedding \\

            \hline

            Natural Language Processing & NLP refers to the use of machine learning to encode and 
            process text to understand it in a similar way to humans, which can be used to allow direct 
            two-way conversation between users and computers. & Deep learning, Tokenization, Sentiment analysis,
            Entity linking

            \\

            \hline
            
            LLMs & Large Language Models are a type of AI dedicated to the recognition and generation of text.
            As suggested by their name, they are trained on enormous amounts of text data, which allows them 
            to have active conversations with users. There are many different LLMs, and as their size and 
            complexity increases, so too does the necessary processing power. &
            Retrieval augmented generation (RAG), Fine-tuning, Prompt engineering, Impact on industry,
            GPT4o, LLaMA, Gemini, Claude
            
            \\

            \hline
            Chatbot \newline Conversational Agent & Software that simulates a natural conversation between the 
            computer and end user. Many chatbots, including the one I intend to develop, utilise recent
            developments such as Generative AI and natural language processing (NLP) to interpret and respond to user queries.
            \autocite{IBMChatbotDef}
            & NLP, ChatGPT, Impact on industry \\

            \hline 

            User Experience (UX) & The end user's overall experience of using a system, such as its ease of use and 
            whether it is enjoyable to use \autocite{UXDict}. In the context of my project, it will refer to the user's 
            ability to smoothly converse with the chatbot and how human-like it is. 
            & Conversational design, usability, market research, human-computer interaction

            \\

            \hline 

        \end{tabular}\label{tab:themes}
    \end{table}


    \pagebreak % REMOVE IF NECESSARY

    \section{Review of Literature}

    \subsection{Artificial Intelligence (AI)}

    % You may notice that some of these autocites are formatted differently. This is because I switched to using Zotero which 
    % generates them for me with different naming schemes. Ones in camelCase were my original ones, then the new ones 
    % formatted as NAME_TITLE_DATE are Zotero.

    Researchers have always wanted to harness the processing power of computers to act in a similar manner 
    indistinguishable from that of humans, most notably from as long ago as 1950, where the question was posed 
    'Can machines think?' \autocite{turing_icomputing_1950}. Ever since, constant innovations were made in computer 
    intelligence and machine learning, from playing games of checkers at a better level than human players \autocite{samuel_studies_1959}
    to classifying the contents of millions of images using convolutional neural networks \autocite{krizhevsky_imagenet_2012}.
    Recently, AI is used across many disciplines and for different purposes to complete tasks faster than, and in some cases better than,
    human workers. \textcite{wirtz_brave_2018} write that 'service robots'~\footnote{Defined as "system-based autonomous and adaptable interfaces that 
    interact, communicate and deliver service to an organization’s customers" \autocite[p.909]{wirtz_brave_2018}} can complete a variety of 
    tangible or intangible actions, such as reading and sending text as a chatbot, seen in Figure \ref{fig:serviceBots}.
    
    \begin{figure}[H]
        \centering
        \includegraphics[width=.8\linewidth]{serviceBots.png}
        \caption{Service robots categorization by task-type and recipient of service \autocite{wirtz_brave_2018}.}
        \label{fig:serviceBots}
    \end{figure}

    Today, AI is still a constantly evolving field that is seeing bleeding-edge developments on a 
    highly frequent basis, and more recently, is becoming instrumental in many people's work and private lives 
    with the introduction of large language models (LLMs) \autocite{AIDigitalAssistants}.
    However, when developing a project that utilises AI, it is important that 
    they are ethical and human-centred in the development process, which is known as Human-Centred AI (HCAI). 
    Another issue is the "black-box problem" - the inability to know an AI's reasoning, meaning that 
    eXplainable AI (XAI) is a growing necessity \autocite{miro-nicolau_comprehensive_2025}. In focusing on 
    HCAI and XAI, the focus shifts from the machine executing the algorithms, and instead to the user and their experience 
    using the AI \autocite{AIEthics}. In his article, Shneiderman strongly advocates for the 
    promotion of HCAI for the benefit of both companies and their users, which is a commonly accepted 
    idea due to the ethical risks of using AI. Because AI calculates outcomes from its training data rather 
    than understanding social norms and perspectives, the use of it in sociotechnical systems poses serious risks 
    due to the 'traps' it can fall into, because it cannot account for every possibility such as the personal tendencies 
    and biases of its users \autocite{selbst_fairness_2019}, and therefore developers require a shift in focus - from the final product
    at the end of development to the development process itself and end users, which also echoes Shneiderman's views. 

    \subsection{Natural language processing (NLP)}
    % \begin{tcolorbox}[colback=blue!5!white,colframe=blue!75!black,title=Will be rewritten in final]
    %     I'm somewhat happy with what I've written here, though I plan to go back and talk about more technical developments
    %     in NLP over time, such as Word2Vec and Seq2Seq.
    % \end{tcolorbox}

    % You've barely cited anything here, this section absolutely needs to be rewritten somewhat; reference
    % the above colorbox for what to put there.


    The ability for a computer to interpret and understand human language greatly enhances the scale of their capabilities. This was 
    recognised during the 1950s, where machine translation from Russian to English was demonstrated for the first time, albeit in a basic form \autocite{zampolli_natural_1994}.
    NLP has persistently been a key topic in computing, and even more so become in recent years, with its applications becoming very wide in scope with modern processing power.
    performing tasks such as sentiment analysis, which is the classification of the intent of a sentence, whether positive or negative for
    example, using recent developments in AI such as recurrent neural networks (RNNs) via libraries like TensorFlow \autocite{abadi_tensorflow_2016}.
    Another use of NLP, as previously mentioned in a rudimentary form in the 1950s, is language translation. Back then, there were very limited technical options compared to 
    those that exist today, and with today's AI, translation can be extremely accurate, albeit more computationally intensive. 
    Both of these applications use RNNs, which are neural networks that are often superior to their alternatives such as convolutional (CNNs)
    and feedforward neural networks (FNNs) when analysing text due to the fact that they can retain information in their internal memory, which can allow them 
    to recall context, allowing them to determine the linguistic relations between sentences within a document \autocite{tang_document_2015}, 
    which is especially useful in conversational interfaces where the user may say "it" to contextually refer to a previous noun from their last prompt. However,
    an even better option is a long short-term memory (LSTM), an updated form of an RNN with an even greater memory capacity that allows it to solve problems 
    with long-term dependencies \autocite{hochreiter_long_1997} that often produce excellent results \autocite{sherstinsky_fundamentals_2020}.

    \pagebreak 

    \subsection{Large language models}
    LLMs are colossal machine learning models that leverage NLP to generate text. To do so, the training data required is immense, 
    reaching 45 terabytes of pure text data for ChatGPT in 2023 \autocite{dwivedi_so_2023}. This data is harvested from the web \autocite{dubey_llama_2024}
    and social media due to it being one of the largest repositories of opinionated text data \autocite{wang_fine-grained_2016}, 
    such as posts on platforms like Facebook and X. However, meticulous care is taken into the specific sources used to remove 
    Personally Identifiable Information (PII) to minimise privacy and ethical concerns \autocite{dubey_llama_2024}. They are currently used widely across 
    an assortment of industries in place of technical support and human resources systems, and can be supplied with text 
    prompts from users which will cause the LLM to generate a response. \textcite{vaswani_attention_2017} proposed the 
    Transformer architecture, which became a staple in LLMs due to the major reduction in necessary processing power to produce higher-quality 
    results. The architecture they proposed underpins many massive LLMs today, including ChatGPT \autocite{brown_language_2020}. Even with this revelation, however, LLMs are still extremely performance-intensive,
    requiring more than 8 top-range server-grade GPUs to run some of the most powerful high-parameter open-source models of today like LLaMA 3.1's 405 billion parameter model \autocite{dubey_llama_2024}.
    However, it is also important to note that the amount of parameters in a model does not entirely account for the quality of its responses, as studied by \textcite{ouyang_training_2022}
    in Figure \ref{fig:LLMPref} wherein their surveys revealed their fine-tuned LLM with over 100x less parameters than a 175 billion parameter 
    GPT3 model would often give answers preferred by its human assessors, which reveals that the fine-tuning of an LLM is of vital importance 
    to the quality of its responses, even moreso than the amount of parameters. Another major innovation in LLMs came in the form of Retrieval-Augmented 
    Generation (RAG), which allows LLMs to generate answers based on an additional external data source \autocite{lewis_retrieval-augmented_2021}, such as a company's own database.
    RAG therefore allows pre-trained LLMs to be attached to another data source and generate text based on that source, which can help to reduce 
    LLM "hallucinations" \autocite{lewis_retrieval-augmented_2021}, which are occurrences where the LLM will fabricate false information as though it were correct, 
    due to the fact that it can retrieve the relevant information it otherwise may not have had.

    \begin{figure}[H] 
        \centering
        \includegraphics[width=.8\linewidth]{ouyangLLMPreference.png}
        \caption{Human evaluations of the GPT models produced by \textcite{ouyang_training_2022}. PPO and PPO-ptx are their models.}
        \label{fig:LLMPref}
    \end{figure}

    % Talk about \autocite{vaswani_attention_2017} here. It's a key paper and was the foundation
    % of GPT (I think). Pivot into RAG, as you're not training your own LLM due to lack of processing power. Decide between Gemini or OpenAI.
    % IIRC Gemini will be far cheaper, possibly free. Maybe go out of your way to speak to Dan about his ideas of a shared OpenAI account to 
    % split costs.

    \subsection{Chatbots / Conversational Agents}
    Conversational agents, better known as chatbots, leverage natural language processing in order to simulate a conversational flow 
    between a user and machine, and have become mainstream products in recent years \autocite{liao_all_2018},
    though have existed as far back as 1966 with the creation of "ELIZA" for the IBM-7094 \autocite{weizenbaum_elizacomputer_1966}.
    As time has passed, advancements in chatbots have occurred in "waves", where each new wave has brought a major innovation \autocite{schobel_charting_2024}.
    As a product of the considerable developments in the field, chatbots are now widely used 
    across industries such as education \autocite{kuhail_interacting_2023}. However, the use of the latest wave of chatbots based on LLMs
    chatbots, especially in educational settings, poses significant risks as studied by \textcite{neumann_llm-driven_2024}
    due to the risk of hallucinations being interpreted as absolute fact, although \textcite{shuster_retrieval_2021} 
    argued that this risk can be greatly reduced through introducing RAG to the backend LLM, which is further backed 
    by the RAG-based chatbot created by \textcite{ge_development_2023}, which they found to also give superior answers
    in their medical field of study to those of a general-purpose chatbot without RAG.  

    \begin{figure}[H] 
        \centering
        \includegraphics[width=.8\linewidth]{ChatbotWaves.png}
        \caption{The five waves of conversational agent research \autocite{schobel_charting_2024}.}
        \label{fig:ChatbotWaves}
    \end{figure}

    % \subsection{Information Retrieval Systems}
    % Either this or RAG should have been a theme, I think. However, to do so would mean either the removal of 
    % another theme (Probably UX) or going over the word count.
    

    \subsection{User experience and Human-Computer Interaction}
    % I'm not too happy with this section. Find some figures or something to bloat it with.
    The way people interact with their devices has drastically evolved over the years, from early MS-DOS command-line 
    interfaces (CLIs) to mouse-based graphical user interfaces (GUIs), to touch screens \autocite{kotian_systematic_2024}, greatly broadening
    the userbase of computers as a whole from exclusively those heavily invested in tech to a vast majority of the world's 
    population. As such, inclusive and accessible design is increasingly important to maximise the audience of any software,
    especially considering the growing disabled population \autocite{putnam_how_2012}. As well as being inclusive, the design 
    should also be user-centred, meaning it should be an iterative process that is constantly taking user feedback 
    into account \autocite{chammas_closer_2015}. However, there are some barriers in this process when developing 
    chatbots, as studied by \textcite{clark_what_2019} in their survey of university students who stated that they would 
    always view a chatbot as a tool, and would not converse with them in the same way as they would a person, which would 
    limit their potential use and hinder the overall design process. 
    In this same context, it is also important to understand that users may struggle
    to get the chatbot to respond with information they want, as their prompts may be poorly understood
    due to issues like overgeneralisation \autocite{zamfirescu-pereira_why_2023}, and that users can quickly 
    grow impatient after around 2 to 6 failed attempts, often branding the product as poor if this occurs \autocite{luger_like_2016}.


    % \section{Theory}
    % You could gamble on the complete non-inclusion of this section, though it may be picked up on.
    % You will have to see after Thursday's meeting.
    
    % As it turns out, you have actually GRAVELY misunderstood this section.
    % This is PART OF EVERY THEME. Technique here will be to find the equations 
    % and algorithms that it's all based on. I expect the word count to go to 
    % 2500 off of this, though given your lengthy intro to the document 
    % that should actually bring the review itself to 2000.
    
    % "Details of how things work. This is very different from the Review, which provides 
    % cursory links between research. It should include design methods (e.g., equations, algorithms) 
    % that will be used and so on. There is no need to start from basics (e.g., V=IR, syntax error) 
    % as the reader will have some knowledge"

    \pagebreak 
    
    \section{Summary}

    % Dead simple section, single paragraph explaining your findings and how you'll apply them to the bot.
    
    In conclusion, this literature review has revealed multiple key areas of focus for the development of the 
    chatbot. The overall design of the chatbot must be iterative and human-centred, and user feedback should 
    be obtained at every possible opportunity to ensure the resultant product is high quality. A deep exploration 
    into AI, specifically in its applications in NLP and LLMs, has revealed that the best option for the chatbot 
    will be to leverage a pre-existing cloud-based LLM's RAG capabilities to attach it to a database of 
    university information, as to do so on a local machine would require an infeasible amount of processing power.
    In doing so, the LLM-based chatbot will be able to give good general answers as well as accurate 
    university-specific answers regarding policies and societies.

    Additionally, the discovery of many issues in the development of chatbots will greatly influence the design 
    process, such as the need for users to be able to access the information they want in as few queries as 
    possible to ensure user retention. Doing so will require prompt engineering to ensure that the LLM backend 
    is generating specific information relevant to university rather than generic information that it may 
    have been pre-trained with that would not be directly relevant.

    \begin{landscape}

    \chapter{Appendix}

    % ALSO UPDATE IT TO SAY DRAFT 1 WAS SUBMITTED BEFORE IT HAD TO BE! SHOWS YOU WERE 
    % ACTIVELY UPDATING THE CHART

    \section{Gantt Chart}

    \begin{figure}[H]
        \centering
        \includegraphics[width=.9\linewidth]{LitReviewGantt.png}
        \caption{The updated Gantt Chart for the development timeline.}
        \label{fig:gantt}
    \end{figure}

    \end{landscape}

    \printbibliography[keyword={refs}, title = {References}]
    \addcontentsline{toc}{chapter}{References}

    % Invisible citing bib sources so that they'll appear in the bibliography, as they won't show up unless cited.
    \nocite{IBMAIDef}
    \nocite{ICOAIDef}
    \nocite{IBMGenAI}
    \nocite{MITGenAI}
    \nocite{CloudflareLLM}
    \nocite{IBMNLP}

    \printbibliography[keyword={bib}, title = {Bibliography~~~~~~~~~~~~\small{Sources consulted but not directly cited}}]
    \addcontentsline{toc}{chapter}{Bibliography}

\end{document}