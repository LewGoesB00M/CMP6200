@article{litSearch,
	title = {Where you search determines what you find: the effects of bibliographic databases on systematic reviews},
	volume = {25},
	issn = {1364-5579},
	url = {https://doi.org/10.1080/13645579.2021.1892378},
	doi = {10.1080/13645579.2021.1892378},
	shorttitle = {Where you search determines what you find},
	abstract = {Systematic literature reviews are common in social research for integrating and synthesising existing research. This paper argues that the outcomes of such reviews are affected by the choice of bibliographic databases. It presents evidence of substantial variation across three large electronic databases (Scopus, Web of Science and {EBSCO}) in a study on employee retention and staff turnover. It considers the specific articles, numbers returned, numbers shared across databases and perceived quality of journals hosting the retrieved articles. Results show that only 130 articles (5.7\% of 2267 retrieved) were found common to all three databases, suggesting that decisions on how and where literature is retrieved can substantially affect the results of systematic reviews and meta-analyses. The findings caution against the use of single databases and claiming comprehensiveness. The paper reflects on how additional literature search methods (e.g., contacting experts, citation indices) and their sequence of use can affect systematic review quality.},
	pages = {409--422},
	number = {3},
	journaltitle = {International Journal of Social Research Methodology},
	author = {Wanyama, Seperia B. and McQuaid, Ronald W. and Kittler, Markus},
	urldate = {2024-10-31},
	date = {2022-05-04},
	publisher = Routledge,
	keywords = {refs},
	file = {Full Text PDF:C\:\\Users\\Lewis\\Zotero\\storage\\W7Z7IEHF\\Wanyama et al. - 2022 - Where you search determines what you find the effects of bibliographic databases on systematic revi.pdf:application/pdf},
}


@article{AIEthics,
	title = {Bridging the Gap Between Ethics and Practice: Guidelines for Reliable, Safe, and Trustworthy Human-centered {AI} Systems},
	volume = {10},
	issn = {2160-6455},
	url = {https://dl.acm.org/doi/10.1145/3419764},
	doi = {10.1145/3419764},
	shorttitle = {Bridging the Gap Between Ethics and Practice},
	abstract = {This article attempts to bridge the gap between widely discussed ethical principles of Human-centered {AI} ({HCAI}) and practical steps for effective governance. Since {HCAI} systems are developed and implemented in multiple organizational structures, I propose 15 recommendations at three levels of governance: team, organization, and industry. The recommendations are intended to increase the reliability, safety, and trustworthiness of {HCAI} systems: (1) reliable systems based on sound software engineering practices, (2) safety culture through business management strategies, and (3) trustworthy certification by independent oversight. Software engineering practices within teams include audit trails to enable analysis of failures, software engineering workflows, verification and validation testing, bias testing to enhance fairness, and explainable user interfaces. The safety culture within organizations comes from management strategies that include leadership commitment to safety, hiring and training oriented to safety, extensive reporting of failures and near misses, internal review boards for problems and future plans, and alignment with industry standard practices. The trustworthiness certification comes from industry-wide efforts that include government interventions and regulation, accounting firms conducting external audits, insurance companies compensating for failures, non-governmental and civil society organizations advancing design principles, and professional organizations and research institutes developing standards, policies, and novel ideas. The larger goal of effective governance is to limit the dangers and increase the benefits of {HCAI} to individuals, organizations, and society.},
	pages = {26:1--26:31},
	number = {4},
	journaltitle = {{ACM} Trans. Interact. Intell. Syst.},
	author = {Shneiderman, Ben},
	urldate = {2024-10-31},
	date = {2020-10-16},
	keywords = {refs},
	file = {Full Text PDF:C\:\\Users\\Lewis\\Zotero\\storage\\HDDRHZGV\\Shneiderman - 2020 - Bridging the Gap Between Ethics and Practice Guidelines for Reliable, Safe, and Trustworthy Human-c.pdf:application/pdf},
}

@article{AIDigitalAssistants,
	title = {{AI}-Based Digital Assistants},
	volume = {61},
	issn = {1867-0202},
	url = {https://doi.org/10.1007/s12599-019-00600-8},
	doi = {10.1007/s12599-019-00600-8},
	pages = {535--544},
	number = {4},
	journaltitle = {Business \& Information Systems Engineering},
	shortjournal = {Bus Inf Syst Eng},
	author = {Maedche, Alexander and Legner, Christine and Benlian, Alexander and Berger, Benedikt and Gimpel, Henner and Hess, Thomas and Hinz, Oliver and Morana, Stefan and Söllner, Matthias},
	urldate = {2024-10-31},
	date = {2019-08-01},
	langid = {english},
	keywords = {refs},
	file = {Full Text PDF:C\:\\Users\\Lewis\\Zotero\\storage\\U6RZZZAC\\Maedche et al. - 2019 - AI-Based Digital Assistants.pdf:application/pdf},
}

% You may notice that some of these entries are formatted differently. This is because I switched to using Zotero which 
% generates them for me with different naming schemes.

@inproceedings{vaswani_attention_2017,
	location = {Red Hook, {NY}, {USA}},
	title = {Attention is all you need},
	isbn = {978-1-5108-6096-4},
	series = {{NIPS}'17},
	abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 {BLEU} on the {WMT} 2014 English-to-German translation task, improving over the existing best results, including ensembles, by over 2 {BLEU}. On the {WMT} 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art {BLEU} score of 41.0 after training for 3.5 days on eight {GPUs}, a small fraction of the training costs of the best models from the literature.},
	pages = {6000--6010},
	doi = {10.48550/arXiv.1706.03762},
	booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
	publisher = {Curran Associates Inc.},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Łukasz and Polosukhin, Illia},
	urldate = {2024-11-04},
	date = {2017-12-04},
	file = {Full Text PDF:C\:\\Users\\Lewis\\Zotero\\storage\\JR84UK2N\\Vaswani et al. - 2017 - Attention is all you need.pdf:application/pdf},
	keywords = {refs}
}


@article{turing_icomputing_1950,
	title = {I.—{COMPUTING} {MACHINERY} {AND} {INTELLIGENCE}},
	volume = {{LIX}},
	issn = {1460-2113, 0026-4423},
	url = {https://academic.oup.com/mind/article/LIX/236/433/986238},
	doi = {10.1093/mind/LIX.236.433},
	pages = {433--460},
	number = {236},
	journaltitle = {Mind},
	author = {Turing, A. M.},
	urldate = {2024-11-04},
	date = {1950-10-01},
	langid = {english},
	keywords = {refs},
	file = {PDF:C\:\\Users\\Lewis\\Zotero\\storage\\EQELPP9J\\Turing - 1950 - I.—COMPUTING MACHINERY AND INTELLIGENCE.pdf:application/pdf},
}


@inproceedings{selbst_fairness_2019,
	location = {New York, {NY}, {USA}},
	title = {Fairness and Abstraction in Sociotechnical Systems},
	isbn = {978-1-4503-6125-5},
	url = {https://dl.acm.org/doi/10.1145/3287560.3287598},
	doi = {10.1145/3287560.3287598},
	series = {{FAT}* '19},
	abstract = {A key goal of the fair-{ML} community is to develop machine-learning based systems that, once introduced into a social context, can achieve social and legal outcomes such as fairness, justice, and due process. Bedrock concepts in computer science---such as abstraction and modular design---are used to define notions of fairness and discrimination, to produce fairness-aware learning algorithms, and to intervene at different stages of a decision-making pipeline to produce "fair" outcomes. In this paper, however, we contend that these concepts render technical interventions ineffective, inaccurate, and sometimes dangerously misguided when they enter the societal context that surrounds decision-making systems. We outline this mismatch with five "traps" that fair-{ML} work can fall into even as it attempts to be more context-aware in comparison to traditional data science. We draw on studies of sociotechnical systems in Science and Technology Studies to explain why such traps occur and how to avoid them. Finally, we suggest ways in which technical designers can mitigate the traps through a refocusing of design in terms of process rather than solutions, and by drawing abstraction boundaries to include social actors rather than purely technical ones.},
	pages = {59--68},
	booktitle = {Proceedings of the Conference on Fairness, Accountability, and Transparency},
	publisher = {Association for Computing Machinery},
	author = {Selbst, Andrew D. and Boyd, Danah and Friedler, Sorelle A. and Venkatasubramanian, Suresh and Vertesi, Janet},
	urldate = {2024-11-06},
	date = {2019-01-29},
	keywords = {refs},
	file = {Full Text PDF:C\:\\Users\\Lewis\\Zotero\\storage\\EFZC4IQ7\\Selbst et al. - 2019 - Fairness and Abstraction in Sociotechnical Systems.pdf:application/pdf},
}


@inproceedings{krizhevsky_imagenet_2012,
	title = {{ImageNet} Classification with Deep Convolutional Neural Networks},
	volume = {25},
	url = {https://proceedings.neurips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html},
	abstract = {We trained a large, deep convolutional neural network to classify the 1.3 million high-resolution images in the {LSVRC}-2010 {ImageNet} training set into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 39.7{\textbackslash}\% and 18.9{\textbackslash}\% which is considerably better than the previous state-of-the-art results. The neural network, which has 60 million parameters and 500,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and two globally connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient {GPU} implementation of convolutional nets. To reduce overfitting in the globally connected layers we employed a new regularization method that proved to be very effective.},
	booktitle = {Advances in Neural Information Processing Systems},
	publisher = {Curran Associates, Inc.},
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
	urldate = {2024-11-06},
	date = {2012},
	doi = {10.1145/3065386},
	keywords = {refs},
	file = {Full Text PDF:C\:\\Users\\Lewis\\Zotero\\storage\\EMSCN29N\\Krizhevsky et al. - 2012 - ImageNet Classification with Deep Convolutional Neural Networks.pdf:application/pdf},
}


@article{samuel_studies_1959,
	title = {Some Studies in Machine Learning Using the Game of Checkers},
	volume = {3},
	issn = {0018-8646},
	url = {https://ieeexplore.ieee.org/abstract/document/5392560},
	doi = {10.1147/rd.33.0210},
	abstract = {Two machine-learning procedures have been investigated in some detail using the game of checkers. Enough work has been done to verify the fact that a computer can be programmed so that it will learn to play a better game of checkers than can be played by the person who wrote the program. Furthermore, it can learn to do this in a remarkably short period of time (8 or 10 hours of machine-playing time) when given only the rules of the game, a sense of direction, and a redundant and incomplete list of parameters which are thought to have something to do with the game, but whose correct signs and relative weights are unknown and unspecified. The principles of machine learning verified by these experiments are, of course, applicable to many other situations.},
	pages = {210--229},
	number = {3},
	journaltitle = {{IBM} Journal of Research and Development},
	author = {Samuel, A. L.},
	urldate = {2024-11-06},
	date = {1959-07},
	note = {Conference Name: {IBM} Journal of Research and Development},
	keywords = {refs},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Lewis\\Zotero\\storage\\RTFHX2SY\\5392560.html:text/html;Submitted Version:C\:\\Users\\Lewis\\Zotero\\storage\\TLDDTG9K\\Samuel - 1959 - Some Studies in Machine Learning Using the Game of Checkers.pdf:application/pdf},
}


@article{wirtz_brave_2018,
	title = {Brave new world: service robots in the frontline},
	volume = {29},
	doi = {10.1108/JOSM-04-2018-0119},
	shorttitle = {Brave new world},
	abstract = {Purpose: The service sector is at an inflection point with regard to productivity gains and service industrialization similar to the industrial revolution in manufacturing that started in the eighteenth century. Robotics in combination with rapidly improving technologies like artificial intelligence ({AI}), mobile, cloud, big data and biometrics will bring opportunities for a wide range of innovations that have the potential to dramatically change service industries. The purpose of this paper is to explore the potential role service robots will play in the future and to advance a research agenda for service researchers. Design/methodology/approach: This paper uses a conceptual approach that is rooted in the service, robotics and {AI} literature. Findings: The contribution of this paper is threefold. First, it provides a definition of service robots, describes their key attributes, contrasts their features and capabilities with those of frontline employees, and provides an understanding for which types of service tasks robots will dominate and where humans will dominate. Second, this paper examines consumer perceptions, beliefs and behaviors as related to service robots, and advances the service robot acceptance model. Third, it provides an overview of the ethical questions surrounding robot-delivered services at the individual, market and societal level. Practical implications: This paper helps service organizations and their management, service robot innovators, programmers and developers, and policymakers better understand the implications of a ubiquitous deployment of service robots. Originality/value: This is the first conceptual paper that systematically examines key dimensions of robot-delivered frontline service and explores how these will differ in the future. © 2018, Jochen Wirtz, Paul G. Patterson, Werner H. Kunz, Thorsten Gruber, Vinh Nhat Lu, Stefanie Paluch and Antje Martins.},
	pages = {907--931},
	number = {5},
	journaltitle = {Journal of Service Management},
	author = {Wirtz, J. and Patterson, P.G. and Kunz, W.H. and Gruber, T. and Lu, V.N. and Paluch, S. and Martins, A.},
	date = {2018},
	keywords = {Artificial intelligence, Consumer behaviour, Ethics, Markets, Privacy, Service robots, refs},
	file = {Full Text:C\:\\Users\\Lewis\\Zotero\\storage\\4QYKKXGC\\Wirtz et al. - 2018 - Brave new world service robots in the frontline.pdf:application/pdf;Snapshot:C\:\\Users\\Lewis\\Zotero\\storage\\FCSMRGYF\\display.html:text/html},
}


@article{miro-nicolau_comprehensive_2025,
	title = {A comprehensive study on fidelity metrics for {XAI}},
	volume = {62},
	doi = {10.1016/j.ipm.2024.103900},
	abstract = {The use of {eXplainable} Artificial Intelligence ({XAI}) systems has introduced a set of challenges that need resolution. Herein, we focus on how to correctly select an {XAI} method, an open questions within the field. The inherent difficulty of this task is due to the lack of a ground truth. Several authors have proposed metrics to approximate the fidelity of different {XAI} methods. These metrics lack verification and have concerning disagreements. In this study, we proposed a novel methodology to verify fidelity metrics, using transparent models. These models allowed us to obtain explanations with perfect fidelity. Our proposal constitutes the first objective benchmark for these metrics, facilitating a comparison of existing proposals, and surpassing existing methods. We applied our benchmark to assess the existing fidelity metrics in two different experiments, each using public datasets comprising 52,000 images. The images from these datasets had a size a 128 by 128 pixels and were synthetic data that simplified the training process. We identified that two fidelity metrics, Faithfulness Estimate and Faithfulness Correlation, obtained the expected perfect results for linear models, showing their ability to approximate fidelity for this kind of methods. However, when present with non-linear models, as the ones most used in the state-of-the-art,all metric values, indicated a lack of fidelity, with the best one showing a 30\% deviation from the expected values for perfect explanation. Our experimentation led us to conclude that the current fidelity metrics are not reliable enough to be used in real scenarios. From this finding, we deemed it necessary to development new metrics, to avoid the detected problems, and we recommend the usage of our proposal as a benchmark within the scientific community to address these limitations. © 2024 The Authors},
	number = {1},
	journaltitle = {Information Processing and Management},
	author = {Miró-Nicolau, M. and Jaume-i-Capó, A. and Moyà-Alcover, G.},
	date = {2025},
	keywords = {Explainable Artificial Intelligence ({XAI}), Fidelity, Objective evaluation, refs},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\Lewis\\Zotero\\storage\\TUEXV8IB\\Miró-Nicolau et al. - 2025 - A comprehensive study on fidelity metrics for XAI.pdf:application/pdf;Snapshot:C\:\\Users\\Lewis\\Zotero\\storage\\5CWT8N4X\\display.html:text/html},
}


@inproceedings{wang_fine-grained_2016,
	title = {Fine-grained sentiment analysis of social media with emotion sensing},
	url = {https://ieeexplore.ieee.org/document/7821783},
	doi = {10.1109/FTC.2016.7821783},
	abstract = {Social media is arguably the richest source of human generated text input. Opinions, feedbacks and critiques provided by internet users reflect attitudes and sentiments towards certain topics, products, or services. The sheer volume of such information makes it effectively impossible for any group of persons to read through. Thus, social media sentiment analysis has become an important area of work to make sense of the social media talk. However, most existing sentiment analysis techniques focus only on the aggregate level, classifying sentiments broadly into positive, neutral or negative, and lack the capabilities to perform fine-grained sentiment analysis. This paper describes a social media analytics engine that employs a social adaptive fuzzy similarity-based classification method to automatically classify text messages into sentiment categories (positive, negative, neutral and mixed), with the ability to identify their prevailing emotion categories (e.g., satisfaction, happiness, excitement, anger, sadness, and anxiety). It is also embedded within an end-to-end social media analysis system that has the capabilities to collect, filter, classify, and analyze social media text data and display a descriptive and predictive analytics dashboard for a given concept. The proposed method has been developed and is ready to be licensed to users.},
	eventtitle = {2016 Future Technologies Conference ({FTC})},
	pages = {1361--1364},
	booktitle = {2016 Future Technologies Conference ({FTC})},
	author = {Wang, Zhaoxia and Chong, Chee Seng and Lan, Landy and Yang, Yinping and Beng Ho, Seng and Tong, Joo Chuan},
	urldate = {2024-11-06},
	date = {2016-12},
	keywords = {emotion, Engines, Information filters, Learning systems, opinion mining, Sensors, sentiment analysis, Sentiment analysis, sentiment classification, social adaptive fuzzy similarity, social media, Social network services, refs},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Lewis\\Zotero\\storage\\8XQIMKTP\\7821783.html:text/html},
}


@article{collobert_natural_2011,
	title = {Natural Language Processing (Almost) from Scratch},
	volume = {12},
	issn = {1532-4435},
	url = {https://dl-acm-org.bcu.idm.oclc.org/doi/10.5555/1953048.2078186},
	abstract = {We propose a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for building a freely available tagging system with good performance and minimal computational requirements.},
	pages = {2493--2537},
	issue = {2/1/2011},
	journaltitle = {J. Mach. Learn. Res.},
	author = {Collobert, Ronan and Weston, Jason and Bottou, Léon and Karlen, Michael and Kavukcuoglu, Koray and Kuksa, Pavel},
	date = {2011-11-01},
	keywords = {refs},
	file = {Full Text PDF:C\:\\Users\\Lewis\\Zotero\\storage\\UL2VSE7A\\Collobert et al. - 2011 - Natural Language Processing (Almost) from Scratch.pdf:application/pdf},
}


@incollection{zampolli_natural_1994,
	location = {Dordrecht},
	title = {Natural Language Processing: A Historical Review},
	isbn = {978-0-7923-2998-5 978-0-585-35958-8},
	url = {http://link.springer.com/10.1007/978-0-585-35958-8_1},
	shorttitle = {Natural Language Processing},
	abstract = {This paper reviews natural language processing ({NLP}) from the late 1940's to the present, seeking to identify its successive trends as these reflect concerns with different problems or the pursuit of different approaches to solving these problems and building systems as wholes. The review distinguishes four phases in the history of {NLP}, characterised respectively by an emphasis on machine translation, by the influence of artificial intelligence, by the adoption of a logico-grammatical style, and by an attack on massive language data. The account considers the significant and salient work in each phase, and concludes with an assessment of where we stand after more than forty years of effort in the field.},
	pages = {3--16},
	booktitle = {Current Issues in Computational Linguistics: In Honour of Don Walker},
	publisher = {Springer Netherlands},
	author = {Jones, Karen Sparck},
	editor = {Zampolli, Antonio and Calzolari, Nicoletta and Palmer, Martha},
	urldate = {2024-11-06},
	date = {1994},
	langid = {english},
	doi = {10.1007/978-0-585-35958-8_1},
	file = {PDF:C\:\\Users\\Lewis\\Zotero\\storage\\A4TEFKSR\\Jones - 1994 - Natural Language Processing A Historical Review.pdf:application/pdf},
}


@inproceedings{abadi_tensorflow_2016,
	location = {Savannah, {GA}},
	title = {{TensorFlow}: A System for Large-Scale Machine Learning},
	isbn = {978-1-931971-33-1},
	url = {https://www.usenix.org/conference/osdi16/technical-sessions/presentation/abadi},
	doi = {10.48550/arXiv.1605.08695},
	pages = {265--283},
	booktitle = {12th {USENIX} Symposium on Operating Systems Design and Implementation ({OSDI} 16)},
	publisher = {{USENIX} Association},
	author = {Abadi, Martín and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael and Kudlur, Manjunath and Levenberg, Josh and Monga, Rajat and Moore, Sherry and Murray, Derek G. and Steiner, Benoit and Tucker, Paul and Vasudevan, Vijay and Warden, Pete and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang},
	date = {2016-11},
	file = {PDF:C\:\\Users\\Lewis\\Zotero\\storage\\4FWHMPTG\\Abadi et al. - TensorFlow A System for Large-Scale Machine Learning.pdf:application/pdf},
}


@inproceedings{tang_document_2015,
	location = {Lisbon, Portugal},
	title = {Document Modeling with Gated Recurrent Neural Network for Sentiment Classification},
	url = {https://aclanthology.org/D15-1167},
	doi = {10.18653/v1/D15-1167},
	eventtitle = {{EMNLP} 2015},
	pages = {1422--1432},
	booktitle = {Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing},
	publisher = {Association for Computational Linguistics},
	author = {Tang, Duyu and Qin, Bing and Liu, Ting},
	editor = {Màrquez, Lluís and Callison-Burch, Chris and Su, Jian},
	urldate = {2024-11-06},
	date = {2015-09},
	keywords = {refs},
	file = {Full Text PDF:C\:\\Users\\Lewis\\Zotero\\storage\\X3HKUTER\\Tang et al. - 2015 - Document Modeling with Gated Recurrent Neural Network for Sentiment Classification.pdf:application/pdf},
}

@misc{brown_language_2020,
	title = {Language Models are Few-Shot Learners},
	url = {http://arxiv.org/abs/2005.14165},
	doi = {10.48550/arXiv.2005.14165},
	abstract = {Recent work has demonstrated substantial gains on many {NLP} tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something which current {NLP} systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches. Specifically, we train {GPT}-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, {GPT}-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model. {GPT}-3 achieves strong performance on many {NLP} datasets, including translation, question-answering, and cloze tasks, as well as several tasks that require on-the-fly reasoning or domain adaptation, such as unscrambling words, using a novel word in a sentence, or performing 3-digit arithmetic. At the same time, we also identify some datasets where {GPT}-3's few-shot learning still struggles, as well as some datasets where {GPT}-3 faces methodological issues related to training on large web corpora. Finally, we find that {GPT}-3 can generate samples of news articles which human evaluators have difficulty distinguishing from articles written by humans. We discuss broader societal impacts of this finding and of {GPT}-3 in general.},
	number = {{arXiv}:2005.14165},
	publisher = {{arXiv}},
	author = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and {McCandlish}, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
	urldate = {2024-11-19},
	date = {2020-07-22},
	eprinttype = {arxiv},
	eprint = {2005.14165},
	keywords = {Computer Science - Computation and Language},
	file = {Preprint PDF:C\:\\Users\\Lewis\\Zotero\\storage\\WYHWSE4V\\Brown et al. - 2020 - Language Models are Few-Shot Learners.pdf:application/pdf;Snapshot:C\:\\Users\\Lewis\\Zotero\\storage\\R2Z4HBQF\\2005.html:text/html},
}

@misc{dubey_llama_2024,
	title = {The Llama 3 Herd of Models},
	url = {http://arxiv.org/abs/2407.21783},
	doi = {10.48550/arXiv.2407.21783},
	abstract = {Modern artificial intelligence ({AI}) systems are powered by foundation models. This paper presents a new set of foundation models, called Llama 3. It is a herd of language models that natively support multilinguality, coding, reasoning, and tool usage. Our largest model is a dense Transformer with 405B parameters and a context window of up to 128K tokens. This paper presents an extensive empirical evaluation of Llama 3. We find that Llama 3 delivers comparable quality to leading language models such as {GPT}-4 on a plethora of tasks. We publicly release Llama 3, including pre-trained and post-trained versions of the 405B parameter language model and our Llama Guard 3 model for input and output safety. The paper also presents the results of experiments in which we integrate image, video, and speech capabilities into Llama 3 via a compositional approach. We observe this approach performs competitively with the state-of-the-art on image, video, and speech recognition tasks. The resulting models are not yet being broadly released as they are still under development.},
	number = {{arXiv}:2407.21783},
	publisher = {{arXiv}},
	author = {Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and Goyal, Anirudh and Hartshorn, Anthony and Yang, Aobo and Mitra, Archi and Sravankumar, Archie and Korenev, Artem and Hinsvark, Arthur and Rao, Arun and Zhang, Aston and Rodriguez, Aurelien and Gregerson, Austen and Spataru, Ava and Roziere, Baptiste and Biron, Bethany and Tang, Binh and Chern, Bobbie and Caucheteux, Charlotte and Nayak, Chaya and Bi, Chloe and Marra, Chris and {McConnell}, Chris and Keller, Christian and Touret, Christophe and Wu, Chunyang and Wong, Corinne and Ferrer, Cristian Canton and Nikolaidis, Cyrus and Allonsius, Damien and Song, Daniel and Pintz, Danielle and Livshits, Danny and Esiobu, David and Choudhary, Dhruv and Mahajan, Dhruv and Garcia-Olano, Diego and Perino, Diego and Hupkes, Dieuwke and Lakomkin, Egor and {AlBadawy}, Ehab and Lobanova, Elina and Dinan, Emily and Smith, Eric Michael and Radenovic, Filip and Zhang, Frank and Synnaeve, Gabriel and Lee, Gabrielle and Anderson, Georgia Lewis and Nail, Graeme and Mialon, Gregoire and Pang, Guan and Cucurell, Guillem and Nguyen, Hailey and Korevaar, Hannah and Xu, Hu and Touvron, Hugo and Zarov, Iliyan and Ibarra, Imanol Arrieta and Kloumann, Isabel and Misra, Ishan and Evtimov, Ivan and Copet, Jade and Lee, Jaewon and Geffert, Jan and Vranes, Jana and Park, Jason and Mahadeokar, Jay and Shah, Jeet and Linde, Jelmer van der and Billock, Jennifer and Hong, Jenny and Lee, Jenya and Fu, Jeremy and Chi, Jianfeng and Huang, Jianyu and Liu, Jiawen and Wang, Jie and Yu, Jiecao and Bitton, Joanna and Spisak, Joe and Park, Jongsoo and Rocca, Joseph and Johnstun, Joshua and Saxe, Joshua and Jia, Junteng and Alwala, Kalyan Vasuden and Upasani, Kartikeya and Plawiak, Kate and Li, Ke and Heafield, Kenneth and Stone, Kevin and El-Arini, Khalid and Iyer, Krithika and Malik, Kshitiz and Chiu, Kuenley and Bhalla, Kunal and Rantala-Yeary, Lauren and Maaten, Laurens van der and Chen, Lawrence and Tan, Liang and Jenkins, Liz and Martin, Louis and Madaan, Lovish and Malo, Lubo and Blecher, Lukas and Landzaat, Lukas and Oliveira, Luke de and Muzzi, Madeline and Pasupuleti, Mahesh and Singh, Mannat and Paluri, Manohar and Kardas, Marcin and Oldham, Mathew and Rita, Mathieu and Pavlova, Maya and Kambadur, Melanie and Lewis, Mike and Si, Min and Singh, Mitesh Kumar and Hassan, Mona and Goyal, Naman and Torabi, Narjes and Bashlykov, Nikolay and Bogoychev, Nikolay and Chatterji, Niladri and Duchenne, Olivier and Çelebi, Onur and Alrassy, Patrick and Zhang, Pengchuan and Li, Pengwei and Vasic, Petar and Weng, Peter and Bhargava, Prajjwal and Dubal, Pratik and Krishnan, Praveen and Koura, Punit Singh and Xu, Puxin and He, Qing and Dong, Qingxiao and Srinivasan, Ragavan and Ganapathy, Raj and Calderer, Ramon and Cabral, Ricardo Silveira and Stojnic, Robert and Raileanu, Roberta and Girdhar, Rohit and Patel, Rohit and Sauvestre, Romain and Polidoro, Ronnie and Sumbaly, Roshan and Taylor, Ross and Silva, Ruan and Hou, Rui and Wang, Rui and Hosseini, Saghar and Chennabasappa, Sahana and Singh, Sanjay and Bell, Sean and Kim, Seohyun Sonia and Edunov, Sergey and Nie, Shaoliang and Narang, Sharan and Raparthy, Sharath and Shen, Sheng and Wan, Shengye and Bhosale, Shruti and Zhang, Shun and Vandenhende, Simon and Batra, Soumya and Whitman, Spencer and Sootla, Sten and Collot, Stephane and Gururangan, Suchin and Borodinsky, Sydney and Herman, Tamar and Fowler, Tara and Sheasha, Tarek and Georgiou, Thomas and Scialom, Thomas and Speckbacher, Tobias and Mihaylov, Todor and Xiao, Tong and Karn, Ujjwal and Goswami, Vedanuj and Gupta, Vibhor and Ramanathan, Vignesh and Kerkez, Viktor and Gonguet, Vincent and Do, Virginie and Vogeti, Vish and Petrovic, Vladan and Chu, Weiwei and Xiong, Wenhan and Fu, Wenyin and Meers, Whitney and Martinet, Xavier and Wang, Xiaodong and Tan, Xiaoqing Ellen and Xie, Xinfeng and Jia, Xuchao and Wang, Xuewei and Goldschlag, Yaelle and Gaur, Yashesh and Babaei, Yasmine and Wen, Yi and Song, Yiwen and Zhang, Yuchen and Li, Yue and Mao, Yuning and Coudert, Zacharie Delpierre and Yan, Zheng and Chen, Zhengxing and Papakipos, Zoe and Singh, Aaditya and Grattafiori, Aaron and Jain, Abha and Kelsey, Adam and Shajnfeld, Adam and Gangidi, Adithya and Victoria, Adolfo and Goldstand, Ahuva and Menon, Ajay and Sharma, Ajay and Boesenberg, Alex and Vaughan, Alex and Baevski, Alexei and Feinstein, Allie and Kallet, Amanda and Sangani, Amit and Yunus, Anam and Lupu, Andrei and Alvarado, Andres and Caples, Andrew and Gu, Andrew and Ho, Andrew and Poulton, Andrew and Ryan, Andrew and Ramchandani, Ankit and Franco, Annie and Saraf, Aparajita and Chowdhury, Arkabandhu and Gabriel, Ashley and Bharambe, Ashwin and Eisenman, Assaf and Yazdan, Azadeh and James, Beau and Maurer, Ben and Leonhardi, Benjamin and Huang, Bernie and Loyd, Beth and Paola, Beto De and Paranjape, Bhargavi and Liu, Bing and Wu, Bo and Ni, Boyu and Hancock, Braden and Wasti, Bram and Spence, Brandon and Stojkovic, Brani and Gamido, Brian and Montalvo, Britt and Parker, Carl and Burton, Carly and Mejia, Catalina and Wang, Changhan and Kim, Changkyu and Zhou, Chao and Hu, Chester and Chu, Ching-Hsiang and Cai, Chris and Tindal, Chris and Feichtenhofer, Christoph and Civin, Damon and Beaty, Dana and Kreymer, Daniel and Li, Daniel and Wyatt, Danny and Adkins, David and Xu, David and Testuggine, Davide and David, Delia and Parikh, Devi and Liskovich, Diana and Foss, Didem and Wang, Dingkang and Le, Duc and Holland, Dustin and Dowling, Edward and Jamil, Eissa and Montgomery, Elaine and Presani, Eleonora and Hahn, Emily and Wood, Emily and Brinkman, Erik and Arcaute, Esteban and Dunbar, Evan and Smothers, Evan and Sun, Fei and Kreuk, Felix and Tian, Feng and Ozgenel, Firat and Caggioni, Francesco and Guzmán, Francisco and Kanayet, Frank and Seide, Frank and Florez, Gabriela Medina and Schwarz, Gabriella and Badeer, Gada and Swee, Georgia and Halpern, Gil and Thattai, Govind and Herman, Grant and Sizov, Grigory and Guangyi and Zhang and Lakshminarayanan, Guna and Shojanazeri, Hamid and Zou, Han and Wang, Hannah and Zha, Hanwen and Habeeb, Haroun and Rudolph, Harrison and Suk, Helen and Aspegren, Henry and Goldman, Hunter and Damlaj, Ibrahim and Molybog, Igor and Tufanov, Igor and Veliche, Irina-Elena and Gat, Itai and Weissman, Jake and Geboski, James and Kohli, James and Asher, Japhet and Gaya, Jean-Baptiste and Marcus, Jeff and Tang, Jeff and Chan, Jennifer and Zhen, Jenny and Reizenstein, Jeremy and Teboul, Jeremy and Zhong, Jessica and Jin, Jian and Yang, Jingyi and Cummings, Joe and Carvill, Jon and Shepard, Jon and {McPhie}, Jonathan and Torres, Jonathan and Ginsburg, Josh and Wang, Junjie and Wu, Kai and U, Kam Hou and Saxena, Karan and Prasad, Karthik and Khandelwal, Kartikay and Zand, Katayoun and Matosich, Kathy and Veeraraghavan, Kaushik and Michelena, Kelly and Li, Keqian and Huang, Kun and Chawla, Kunal and Lakhotia, Kushal and Huang, Kyle and Chen, Lailin and Garg, Lakshya and A, Lavender and Silva, Leandro and Bell, Lee and Zhang, Lei and Guo, Liangpeng and Yu, Licheng and Moshkovich, Liron and Wehrstedt, Luca and Khabsa, Madian and Avalani, Manav and Bhatt, Manish and Tsimpoukelli, Maria and Mankus, Martynas and Hasson, Matan and Lennie, Matthew and Reso, Matthias and Groshev, Maxim and Naumov, Maxim and Lathi, Maya and Keneally, Meghan and Seltzer, Michael L. and Valko, Michal and Restrepo, Michelle and Patel, Mihir and Vyatskov, Mik and Samvelyan, Mikayel and Clark, Mike and Macey, Mike and Wang, Mike and Hermoso, Miquel Jubert and Metanat, Mo and Rastegari, Mohammad and Bansal, Munish and Santhanam, Nandhini and Parks, Natascha and White, Natasha and Bawa, Navyata and Singhal, Nayan and Egebo, Nick and Usunier, Nicolas and Laptev, Nikolay Pavlovich and Dong, Ning and Zhang, Ning and Cheng, Norman and Chernoguz, Oleg and Hart, Olivia and Salpekar, Omkar and Kalinli, Ozlem and Kent, Parkin and Parekh, Parth and Saab, Paul and Balaji, Pavan and Rittner, Pedro and Bontrager, Philip and Roux, Pierre and Dollar, Piotr and Zvyagina, Polina and Ratanchandani, Prashant and Yuvraj, Pritish and Liang, Qian and Alao, Rachad and Rodriguez, Rachel and Ayub, Rafi and Murthy, Raghotham and Nayani, Raghu and Mitra, Rahul and Li, Raymond and Hogan, Rebekkah and Battey, Robin and Wang, Rocky and Maheswari, Rohan and Howes, Russ and Rinott, Ruty and Bondu, Sai Jayesh and Datta, Samyak and Chugh, Sara and Hunt, Sara and Dhillon, Sargun and Sidorov, Sasha and Pan, Satadru and Verma, Saurabh and Yamamoto, Seiji and Ramaswamy, Sharadh and Lindsay, Shaun and Lindsay, Shaun and Feng, Sheng and Lin, Shenghao and Zha, Shengxin Cindy and Shankar, Shiva and Zhang, Shuqiang and Zhang, Shuqiang and Wang, Sinong and Agarwal, Sneha and Sajuyigbe, Soji and Chintala, Soumith and Max, Stephanie and Chen, Stephen and Kehoe, Steve and Satterfield, Steve and Govindaprasad, Sudarshan and Gupta, Sumit and Cho, Sungmin and Virk, Sunny and Subramanian, Suraj and Choudhury, Sy and Goldman, Sydney and Remez, Tal and Glaser, Tamar and Best, Tamara and Kohler, Thilo and Robinson, Thomas and Li, Tianhe and Zhang, Tianjun and Matthews, Tim and Chou, Timothy and Shaked, Tzook and Vontimitta, Varun and Ajayi, Victoria and Montanez, Victoria and Mohan, Vijai and Kumar, Vinay Satish and Mangla, Vishal and Albiero, Vítor and Ionescu, Vlad and Poenaru, Vlad and Mihailescu, Vlad Tiberiu and Ivanov, Vladimir and Li, Wei and Wang, Wenchen and Jiang, Wenwen and Bouaziz, Wes and Constable, Will and Tang, Xiaocheng and Wang, Xiaofang and Wu, Xiaojian and Wang, Xiaolan and Xia, Xide and Wu, Xilun and Gao, Xinbo and Chen, Yanjun and Hu, Ye and Jia, Ye and Qi, Ye and Li, Yenda and Zhang, Yilin and Zhang, Ying and Adi, Yossi and Nam, Youngjin and Yu and Wang and Hao, Yuchen and Qian, Yundi and He, Yuzi and Rait, Zach and {DeVito}, Zachary and Rosnbrick, Zef and Wen, Zhaoduo and Yang, Zhenyu and Zhao, Zhiwei},
	urldate = {2024-11-07},
	date = {2024-08-15},
	eprinttype = {arxiv},
	eprint = {2407.21783},
	keywords = {refs, Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computer Vision and Pattern Recognition},
	file = {Preprint PDF:C\:\\Users\\Lewis\\Zotero\\storage\\ZG29H9VA\\Dubey et al. - 2024 - The Llama 3 Herd of Models.pdf:application/pdf;Snapshot:C\:\\Users\\Lewis\\Zotero\\storage\\G9NBSJET\\2407.html:text/html},
}

@misc{ouyang_training_2022,
	title = {Training language models to follow instructions with human feedback},
	url = {http://arxiv.org/abs/2203.02155},
	doi = {10.48550/arXiv.2203.02155},
	abstract = {Making language models bigger does not inherently make them better at following a user's intent. For example, large language models can generate outputs that are untruthful, toxic, or simply not helpful to the user. In other words, these models are not aligned with their users. In this paper, we show an avenue for aligning language models with user intent on a wide range of tasks by fine-tuning with human feedback. Starting with a set of labeler-written prompts and prompts submitted through the {OpenAI} {API}, we collect a dataset of labeler demonstrations of the desired model behavior, which we use to fine-tune {GPT}-3 using supervised learning. We then collect a dataset of rankings of model outputs, which we use to further fine-tune this supervised model using reinforcement learning from human feedback. We call the resulting models {InstructGPT}. In human evaluations on our prompt distribution, outputs from the 1.3B parameter {InstructGPT} model are preferred to outputs from the 175B {GPT}-3, despite having 100x fewer parameters. Moreover, {InstructGPT} models show improvements in truthfulness and reductions in toxic output generation while having minimal performance regressions on public {NLP} datasets. Even though {InstructGPT} still makes simple mistakes, our results show that fine-tuning with human feedback is a promising direction for aligning language models with human intent.},
	number = {{arXiv}:2203.02155},
	publisher = {{arXiv}},
	author = {Ouyang, Long and Wu, Jeff and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll L. and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and Schulman, John and Hilton, Jacob and Kelton, Fraser and Miller, Luke and Simens, Maddie and Askell, Amanda and Welinder, Peter and Christiano, Paul and Leike, Jan and Lowe, Ryan},
	urldate = {2024-11-10},
	date = {2022-03-04},
	eprinttype = {arxiv},
	eprint = {2203.02155},
	keywords = {refs, Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {Preprint PDF:C\:\\Users\\Lewis\\Zotero\\storage\\75NKNNSK\\Ouyang et al. - 2022 - Training language models to follow instructions with human feedback.pdf:application/pdf;Snapshot:C\:\\Users\\Lewis\\Zotero\\storage\\D4RMKF3E\\2203.html:text/html},
}


@article{dwivedi_so_2023,
	title = {“So what if {ChatGPT} wrote it?” Multidisciplinary perspectives on opportunities, challenges and implications of generative conversational {AI} for research, practice and policy},
	volume = {71},
	doi = {10.1016/j.ijinfomgt.2023.102642},
	shorttitle = {“So what if {ChatGPT} wrote it?},
	abstract = {Transformative artificially intelligent tools, such as {ChatGPT}, designed to generate sophisticated text indistinguishable from that produced by a human, are applicable across a wide range of contexts. The technology presents opportunities as well as, often ethical and legal, challenges, and has the potential for both positive and negative impacts for organisations, society, and individuals. Offering multi-disciplinary insight into some of these, this article brings together 43 contributions from experts in fields such as computer science, marketing, information systems, education, policy, hospitality and tourism, management, publishing, and nursing. The contributors acknowledge {ChatGPT}'s capabilities to enhance productivity and suggest that it is likely to offer significant gains in the banking, hospitality and tourism, and information technology industries, and enhance business activities, such as management and marketing. Nevertheless, they also consider its limitations, disruptions to practices, threats to privacy and security, and consequences of biases, misuse, and misinformation. However, opinion is split on whether {ChatGPT}'s use should be restricted or legislated. Drawing on these contributions, the article identifies questions requiring further research across three thematic areas: knowledge, transparency, and ethics; digital transformation of organisations and societies; and teaching, learning, and scholarly research. The avenues for further research include: identifying skills, resources, and capabilities needed to handle generative {AI}; examining biases of generative {AI} attributable to training datasets and processes; exploring business and societal contexts best suited for generative {AI} implementation; determining optimal combinations of human and generative {AI} for various tasks; identifying ways to assess accuracy of text produced by generative {AI}; and uncovering the ethical and legal issues in using generative {AI} across different contexts. © 2023 The Authors},
	journaltitle = {International Journal of Information Management},
	author = {Dwivedi, Y.K. and Kshetri, N. and Hughes, L. and Slade, E.L. and Jeyaraj, A. and Kar, A.K. and Baabdullah, A.M. and Koohang, A. and Raghavan, V. and Ahuja, M. and Albanna, H. and Albashrawi, M.A. and Al-Busaidi, A.S. and Balakrishnan, J. and Barlette, Y. and Basu, S. and Bose, I. and Brooks, L. and Buhalis, D. and Carter, L. and Chowdhury, S. and Crick, T. and Cunningham, S.W. and Davies, G.H. and Davison, R.M. and Dé, R. and Dennehy, D. and Duan, Y. and Dubey, R. and Dwivedi, R. and Edwards, J.S. and Flavián, C. and Gauld, R. and Grover, V. and Hu, M.-C. and Janssen, M. and Jones, P. and Junglas, I. and Khorana, S. and Kraus, S. and Larsen, K.R. and Latreille, P. and Laumer, S. and Malik, F.T. and Mardani, A. and Mariani, M. and Mithas, S. and Mogaji, E. and Nord, J.H. and O'Connor, S. and Okumus, F. and Pagani, M. and Pandey, N. and Papagiannidis, S. and Pappas, I.O. and Pathak, N. and Pries-Heje, J. and Raman, R. and Rana, N.P. and Rehm, S.-V. and Ribeiro-Navarrete, S. and Richter, A. and Rowe, F. and Sarker, S. and Stahl, B.C. and Tiwari, M.K. and van der Aalst, W. and Venkatesh, V. and Viglia, G. and Wade, M. and Walton, P. and Wirtz, J. and Wright, R.},
	date = {2023},
	keywords = {refs, {ChatGPT}, Conversational agent, Generative {AI}, Generative artificial intelligence, Large language models},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\Lewis\\Zotero\\storage\\EBECUKWR\\Dwivedi et al. - 2023 - “So what if ChatGPT wrote it” Multidisciplinary perspectives on opportunities, challenges and impli.pdf:application/pdf;Snapshot:C\:\\Users\\Lewis\\Zotero\\storage\\6Z6XGMDZ\\display.html:text/html},
}


@misc{lewis_retrieval-augmented_2021,
	title = {Retrieval-Augmented Generation for Knowledge-Intensive {NLP} Tasks},
	url = {http://arxiv.org/abs/2005.11401},
	doi = {10.48550/arXiv.2005.11401},
	abstract = {Large pre-trained language models have been shown to store factual knowledge in their parameters, and achieve state-of-the-art results when fine-tuned on downstream {NLP} tasks. However, their ability to access and precisely manipulate knowledge is still limited, and hence on knowledge-intensive tasks, their performance lags behind task-specific architectures. Additionally, providing provenance for their decisions and updating their world knowledge remain open research problems. Pre-trained models with a differentiable access mechanism to explicit non-parametric memory can overcome this issue, but have so far been only investigated for extractive downstream tasks. We explore a general-purpose fine-tuning recipe for retrieval-augmented generation ({RAG}) -- models which combine pre-trained parametric and non-parametric memory for language generation. We introduce {RAG} models where the parametric memory is a pre-trained seq2seq model and the non-parametric memory is a dense vector index of Wikipedia, accessed with a pre-trained neural retriever. We compare two {RAG} formulations, one which conditions on the same retrieved passages across the whole generated sequence, the other can use different passages per token. We fine-tune and evaluate our models on a wide range of knowledge-intensive {NLP} tasks and set the state-of-the-art on three open domain {QA} tasks, outperforming parametric seq2seq models and task-specific retrieve-and-extract architectures. For language generation tasks, we find that {RAG} models generate more specific, diverse and factual language than a state-of-the-art parametric-only seq2seq baseline.},
	number = {{arXiv}:2005.11401},
	publisher = {{arXiv}},
	author = {Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and Küttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rocktäschel, Tim and Riedel, Sebastian and Kiela, Douwe},
	urldate = {2024-11-10},
	date = {2021-04-12},
	eprinttype = {arxiv},
	eprint = {2005.11401},
	keywords = {refs, Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {Preprint PDF:C\:\\Users\\Lewis\\Zotero\\storage\\D6J65Q3M\\Lewis et al. - 2021 - Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf:application/pdf;Snapshot:C\:\\Users\\Lewis\\Zotero\\storage\\P6USX7KJ\\2005.html:text/html},
}

@inproceedings{laugwitz_construction_2008,
	location = {Berlin, Heidelberg},
	title = {Construction and Evaluation of a User Experience Questionnaire},
	isbn = {978-3-540-89350-9},
	doi = {10.1007/978-3-540-89350-9_6},
	abstract = {An end-user questionnaire to measure user experience quickly in a simple and immediate way while covering a preferably comprehensive impression of the product user experience was the goal of the reported construction process. An empirical approach for the item selection was used to ensure practical relevance of items. Usability experts collected terms and statements on user experience and usability, including ‘hard’ as well as ‘soft’ aspects. These statements were consolidated and transformed into a first questionnaire version containing 80 bipolar items. It was used to measure the user experience of software products in several empirical studies. Data were subjected to a factor analysis which resulted in the construction of a 26 item questionnaire including the six factors Attractiveness, Perspicuity, Efficiency, Dependability, Stimulation, and Novelty. Studies conducted for the original German questionnaire and an English version indicate a satisfactory level of reliability and construct validity.},
	pages = {63--76},
	booktitle = {{HCI} and Usability for Education and Work},
	publisher = {Springer},
	author = {Laugwitz, Bettina and Held, Theo and Schrepp, Martin},
	editor = {Holzinger, Andreas},
	date = {2008},
	langid = {english},
	keywords = {refs, Perceived usability, Questionnaire, Software evaluation, Usability assessment, User experience, User satisfaction},
	file = {Full Text PDF:C\:\\Users\\Lewis\\Zotero\\storage\\P767UFQN\\Laugwitz et al. - 2008 - Construction and Evaluation of a User Experience Questionnaire.pdf:application/pdf},
}


@inproceedings{kotian_systematic_2024,
	title = {A Systematic Review on Human and Computer Interaction},
	url = {https://ieeexplore.ieee.org/document/10467622},
	doi = {10.1109/IDCIoT59759.2024.10467622},
	abstract = {As technology continues to advance at an unprecedented pace, the interaction between humans and computers has become an integral part of our daily lives. This study provides a comprehensive review of the evolving landscape of human-computer interaction ({HCI}) research, focusing on the key concepts, methodologies, and advancements in this interdisciplinary field. The review begins by presenting an overview of the historical evolution of {HCI}, tracing its roots from early command-line interfaces to the current era of intuitive touchscreens and voice recognition systems. The fundamental principles of {HCI}, including usability, accessibility, and user-centered design, are examined in detail, highlighting their significance in enhancing the overall user experience. Moreover, the review explores various interaction modalities that have emerged over the years, such as graphical user interfaces, haptic feedback, augmented reality, and virtual reality. It examines the strengths, limitations, and potential applications of these modalities, shedding light on the future possibilities they hold for human-computer interaction. Furthermore, the review delves into the emerging trends in {HCI} research, including natural language processing, gesture recognition, machine learning, and affective computing. These advancements have paved the way for more personalized and adaptive interfaces, enabling computers to understand and respond to human emotions and intentions, thereby fostering deeper levels of engagement and satisfaction. The study also addresses the challenges and ethical considerations associated with human-computer interaction, such as privacy concerns, data security, and algorithmic biases. It emphasizes the importance of designing inclusive and ethical systems that respect users' rights and values.},
	eventtitle = {2024 2nd International Conference on Intelligent Data Communication Technologies and Internet of Things ({IDCIoT})},
	pages = {1214--1218},
	booktitle = {2024 2nd International Conference on Intelligent Data Communication Technologies and Internet of Things ({IDCIoT})},
	author = {Kotian, Abhijith L and Nandipi, Reshna and M, Ushag and S, Usha Rani and {VARSHAUK} and T, Veena G},
	urldate = {2024-11-11},
	date = {2024-01},
	keywords = {refs, Augmented Reality ({AR}), Computers, Ethics, Graphical User Interfaces ({GUI}), Human-computer interaction ({HCI}), Reviews, Speech recognition, Systematics, Touch sensitive screens, User centered design, User-centered Design ({UCD}), Virtual Reality ({VR})},
	file = {Full Text PDF:C\:\\Users\\Lewis\\Zotero\\storage\\JALLCN3B\\Kotian et al. - 2024 - A Systematic Review on Human and Computer Interaction.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\Lewis\\Zotero\\storage\\Z5HX6REZ\\10467622.html:text/html},
}


@inproceedings{putnam_how_2012,
	location = {New York, {NY}, {USA}},
	title = {How do professionals who create computing technologies consider accessibility?},
	isbn = {978-1-4503-1321-6},
	url = {https://dl.acm.org/doi/10.1145/2384916.2384932},
	doi = {10.1145/2384916.2384932},
	series = {{ASSETS} '12},
	abstract = {In this paper, we present survey findings about how user experience ({UX}) and human-computer interaction ({HCI}) professionals, who create information and communication technologies ({ICTs}), reported considering accessibility in their work. Participants (N = 199) represented a wide range of job titles and nationalities. We found that most respondents (87\%, N = 173) reported that accessibility was important or very important in their work; however, when considerations for accessibility were discussed in an open-ended question (N =185) the scope was limited. Additionally, we found that aspects of empathy and professional experience were associated with how accessibility considerations were reported. We also found that many respondents indicated that decisions about accessibility were not in their control. We argue that a better understanding about how accessibility is considered by professionals has implications for academic programs in {HCI} and {UX} as to how well programs are preparing students to consider and advocate for inclusive design.},
	pages = {87--94},
	booktitle = {Proceedings of the 14th international {ACM} {SIGACCESS} conference on Computers and accessibility},
	publisher = {Association for Computing Machinery},
	author = {Putnam, Cynthia and Wozniak, Kathryn and Zefeldt, Mary Jo and Cheng, Jinghui and Caputo, Morgan and Duffield, Carl},
	urldate = {2024-11-11},
	date = {2012-10-22},
	keywords = {refs},
	file = {Full Text PDF:C\:\\Users\\Lewis\\Zotero\\storage\\56KGJF2W\\Putnam et al. - 2012 - How do professionals who create computing technologies consider accessibility.pdf:application/pdf},
}


@inproceedings{zamfirescu-pereira_why_2023,
	location = {New York, {NY}, {USA}},
	title = {Why Johnny Can’t Prompt: How Non-{AI} Experts Try (and Fail) to Design {LLM} Prompts},
	isbn = {978-1-4503-9421-5},
	url = {https://dl.acm.org/doi/10.1145/3544548.3581388},
	doi = {10.1145/3544548.3581388},
	series = {{CHI} '23},
	shorttitle = {Why Johnny Can’t Prompt},
	abstract = {Pre-trained large language models (“{LLMs}”) like {GPT}-3 can engage in fluent, multi-turn instruction-taking out-of-the-box, making them attractive materials for designing natural language interactions. Using natural language to steer {LLM} outputs (“prompting”) has emerged as an important design technique potentially accessible to non-{AI}-experts. Crafting effective prompts can be challenging, however, and prompt-based interactions are brittle. Here, we explore whether non-{AI}-experts can successfully engage in “end-user prompt engineering” using a design probe—a prototype {LLM}-based chatbot design tool supporting development and systematic evaluation of prompting strategies. Ultimately, our probe participants explored prompt designs opportunistically, not systematically, and struggled in ways echoing end-user programming systems and interactive machine learning systems. Expectations stemming from human-to-human instructional experiences, and a tendency to overgeneralize, were barriers to effective prompt design. These findings have implications for non-{AI}-expert-facing {LLM}-based tool design and for improving {LLM}-and-prompt literacy among programmers and the public, and present opportunities for further research.},
	pages = {1--21},
	booktitle = {Proceedings of the 2023 {CHI} Conference on Human Factors in Computing Systems},
	publisher = {Association for Computing Machinery},
	author = {Zamfirescu-Pereira, J.D. and Wong, Richmond Y. and Hartmann, Bjoern and Yang, Qian},
	urldate = {2024-11-11},
	date = {2023-04-19},
	keywords = {refs},
	file = {Full Text PDF:C\:\\Users\\Lewis\\Zotero\\storage\\WTDQFDZB\\Zamfirescu-Pereira et al. - 2023 - Why Johnny Can’t Prompt How Non-AI Experts Try (and Fail) to Design LLM Prompts.pdf:application/pdf},
}


@inproceedings{luger_like_2016,
	location = {New York, {NY}, {USA}},
	title = {"Like Having a Really Bad {PA}": The Gulf between User Expectation and Experience of Conversational Agents},
	isbn = {978-1-4503-3362-7},
	url = {https://dl.acm.org/doi/10.1145/2858036.2858288},
	doi = {10.1145/2858036.2858288},
	series = {{CHI} '16},
	shorttitle = {"Like Having a Really Bad {PA}"},
	abstract = {The past four years have seen the rise of conversational agents ({CAs}) in everyday life. Apple, Microsoft, Amazon, Google and Facebook have all embedded proprietary {CAs} within their software and, increasingly, conversation is becoming a key mode of human-computer interaction. Whilst we have long been familiar with the notion of computers that speak, the investigative concern within {HCI} has been upon multimodality rather than dialogue alone, and there is no sense of how such interfaces are used in everyday life. This paper reports the findings of interviews with 14 users of {CAs} in an effort to understand the current interactional factors affecting everyday use. We find user expectations dramatically out of step with the operation of the systems, particularly in terms of known machine intelligence, system capability and goals. Using Norman's 'gulfs of execution and evaluation' [30] we consider the implications of these findings for the design of future systems.},
	pages = {5286--5297},
	booktitle = {Proceedings of the 2016 {CHI} Conference on Human Factors in Computing Systems},
	publisher = {Association for Computing Machinery},
	author = {Luger, Ewa and Sellen, Abigail},
	urldate = {2024-11-10},
	date = {2016-05-07},
	keywords = {refs},
	file = {Full Text PDF:C\:\\Users\\Lewis\\Zotero\\storage\\G44KWCG4\\Luger and Sellen - 2016 - Like Having a Really Bad PA The Gulf between User Expectation and Experience of Conversational Ag.pdf:application/pdf},
}


@article{chammas_closer_2015,
	title = {A Closer Look on the User Centred Design},
	volume = {3},
	issn = {2351-9789},
	url = {https://www.sciencedirect.com/science/article/pii/S2351978915006575},
	doi = {10.1016/j.promfg.2015.07.656},
	series = {6th International Conference on Applied Human Factors and Ergonomics ({AHFE} 2015) and the Affiliated Conferences, {AHFE} 2015},
	abstract = {This paper discusses the User-Centred Design approach. It presents {UCD} assumptions and concepts, the benefits for users of the products developed under it, and the complications that this practice can bring, since implies in constant iterations and user omnipresence. As a result, we discuss a possible increment of time and budget as well as reviews on this approach front to the market urgency of technology and innovation. It can be seen that although each situation deserves appropriate adjustments for the profile, the best design is still the user-centred. Examples of this approach application with children enhance the discussion over its flexibility and the gains of design projects oriented by user needs and desires.},
	pages = {5397--5404},
	journaltitle = {Procedia Manufacturing},
	shortjournal = {Procedia Manufacturing},
	author = {Chammas, Adriana and Quaresma, Manuela and Mont’Alvão, Cláudia},
	urldate = {2024-11-11},
	date = {2015-01-01},
	keywords = {refs, Children, Methodology, User-Centred Design},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\Lewis\\Zotero\\storage\\KAWKMMTB\\Chammas et al. - 2015 - A Closer Look on the User Centred Design.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Lewis\\Zotero\\storage\\8FXHL75Q\\S2351978915006575.html:text/html},
}


@inproceedings{clark_what_2019,
	location = {New York, {NY}, {USA}},
	title = {What Makes a Good Conversation? Challenges in Designing Truly Conversational Agents},
	isbn = {978-1-4503-5970-2},
	url = {https://dl.acm.org/doi/10.1145/3290605.3300705},
	doi = {10.1145/3290605.3300705},
	series = {{CHI} '19},
	shorttitle = {What Makes a Good Conversation?},
	abstract = {Conversational agents promise conversational interaction but fail to deliver. Efforts often emulate functional rules from human speech, without considering key characteristics that conversation must encapsulate. Given its potential in supporting long-term human-agent relationships, it is paramount that {HCI} focuses efforts on delivering this promise. We aim to understand what people value in conversation and how this should manifest in agents. Findings from a series of semi-structured interviews show people make a clear dichotomy between social and functional roles of conversation, emphasising the long-term dynamics of bond and trust along with the importance of context and relationship stage in the types of conversations they have. People fundamentally questioned the need for bond and common ground in agent communication, shifting to more utilitarian definitions of conversational qualities. Drawing on these findings we discuss key challenges for conversational agent design, most notably the need to redefine the design parameters for conversational agent interaction.},
	pages = {1--12},
	booktitle = {Proceedings of the 2019 {CHI} Conference on Human Factors in Computing Systems},
	publisher = {Association for Computing Machinery},
	author = {Clark, Leigh and Pantidi, Nadia and Cooney, Orla and Doyle, Philip and Garaialde, Diego and Edwards, Justin and Spillane, Brendan and Gilmartin, Emer and Murad, Christine and Munteanu, Cosmin and Wade, Vincent and Cowan, Benjamin R.},
	urldate = {2024-11-11},
	date = {2019-05-02},
	keywords = {refs},
	file = {Full Text PDF:C\:\\Users\\Lewis\\Zotero\\storage\\EXWP9RYD\\Clark et al. - 2019 - What Makes a Good Conversation Challenges in Designing Truly Conversational Agents.pdf:application/pdf},
}


@article{hochreiter_long_1997,
	title = {Long Short-Term Memory},
	volume = {9},
	issn = {0899-7667},
	url = {https://doi.org/10.1162/neco.1997.9.8.1735},
	doi = {10.1162/neco.1997.9.8.1735},
	abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory ({LSTM}). Truncating the gradient where this does not do harm, {LSTM} can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. {LSTM} is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, {LSTM} leads to many more successful runs, and learns much faster. {LSTM} also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
	pages = {1735--1780},
	number = {8},
	journaltitle = {Neural Comput.},
	author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
	urldate = {2024-11-11},
	keywords = {refs},
	date = {1997-11-01},
}


@article{sherstinsky_fundamentals_2020,
	title = {Fundamentals of Recurrent Neural Network ({RNN}) and Long Short-Term Memory ({LSTM}) network},
	volume = {404},
	issn = {0167-2789},
	url = {https://www.sciencedirect.com/science/article/pii/S0167278919305974},
	doi = {10.1016/j.physd.2019.132306},
	abstract = {Because of their effectiveness in broad practical applications, {LSTM} networks have received a wealth of coverage in scientific journals, technical blogs, and implementation guides. However, in most articles, the inference formulas for the {LSTM} network and its parent, {RNN}, are stated axiomatically, while the training formulas are omitted altogether. In addition, the technique of “unrolling” an {RNN} is routinely presented without justification throughout the literature. The goal of this tutorial is to explain the essential {RNN} and {LSTM} fundamentals in a single document. Drawing from concepts in Signal Processing, we formally derive the canonical {RNN} formulation from differential equations. We then propose and prove a precise statement, which yields the {RNN} unrolling technique. We also review the difficulties with training the standard {RNN} and address them by transforming the {RNN} into the “Vanilla {LSTM}”1 1The nickname “Vanilla {LSTM}” symbolizes this model’s flexibility and generality (Greff et al., 2015). network through a series of logical arguments. We provide all equations pertaining to the {LSTM} system together with detailed descriptions of its constituent entities. Albeit unconventional, our choice of notation and the method for presenting the {LSTM} system emphasizes ease of understanding. As part of the analysis, we identify new opportunities to enrich the {LSTM} system and incorporate these extensions into the Vanilla {LSTM} network, producing the most general {LSTM} variant to date. The target reader has already been exposed to {RNNs} and {LSTM} networks through numerous available resources and is open to an alternative pedagogical approach. A Machine Learning practitioner seeking guidance for implementing our new augmented {LSTM} model in software for experimentation and research will find the insights and derivations in this treatise valuable as well.},
	pages = {132306},
	journaltitle = {Physica D: Nonlinear Phenomena},
	shortjournal = {Physica D: Nonlinear Phenomena},
	author = {Sherstinsky, Alex},
	urldate = {2024-11-11},
	date = {2020-03-01},
	keywords = {refs, Convolutional input context windows, External input gate, {LSTM}, {RNN}, {RNN} unfolding/unrolling},
	file = {ScienceDirect Snapshot:C\:\\Users\\Lewis\\Zotero\\storage\\DYDMNWWK\\S0167278919305974.html:text/html;Submitted Version:C\:\\Users\\Lewis\\Zotero\\storage\\PJUIPYIA\\Sherstinsky - 2020 - Fundamentals of Recurrent Neural Network (RNN) and Long Short-Term Memory (LSTM) network.pdf:application/pdf},
}


@article{ashfaq_i_2020,
	title = {I, Chatbot: Modeling the determinants of users’ satisfaction and continuance intention of {AI}-powered service agents},
	volume = {54},
	issn = {0736-5853},
	url = {https://www.sciencedirect.com/science/article/pii/S0736585320301325},
	doi = {10.1016/j.tele.2020.101473},
	shorttitle = {I, Chatbot},
	abstract = {Chatbots are mainly text-based conversational agents that simulate conversations with users. This study aims to investigate drivers of users’ satisfaction and continuance intention toward chatbot-based customer service. We propose an analytical framework combining the expectation-confirmation model ({ECM}), information system success ({ISS}) model, {TAM}, and the need for interaction with a service employee ({NFI}-{SE}). Analysis of data collected from 370 actual chatbot users reveals that information quality ({IQ}) and service quality ({SQ}) positively influence consumers’ satisfaction, and that perceived enjoyment ({PE}), perceived usefulness ({PU}), and perceived ease of use ({PEOU}) are significant predictors of continuance intention ({CI}). The need for interaction with an employee moderates the effects of {PEOU} and {PU} on satisfaction. The findings also revealed that satisfaction with chatbot e-service is a strong determinant and predictor of users’ {CI} toward chatbots. Thus, chatbots should enhance their information and service quality to increase users’ satisfaction. The findings imply that digital technologies services, such as chatbots, could be combined with human service employees to satisfy digital users.},
	pages = {101473},
	journaltitle = {Telematics and Informatics},
	shortjournal = {Telematics and Informatics},
	author = {Ashfaq, Muhammad and Yun, Jiang and Yu, Shubin and Loureiro, Sandra Maria Correia},
	urldate = {2024-11-19},
	date = {2020-11-01},
	keywords = {refs, Chatbots, Continuance intention, {ECM}, {ISS} model, Satisfaction, {TAM}, The need for interaction},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\Lewis\\Zotero\\storage\\W635WNCQ\\Ashfaq et al. - 2020 - I, Chatbot Modeling the determinants of users’ satisfaction and continuance intention of AI-powered.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Lewis\\Zotero\\storage\\A8HVVG6W\\S0736585320301325.html:text/html},
}


@inproceedings{liao_all_2018,
	location = {New York, {NY}, {USA}},
	title = {All Work and No Play?},
	isbn = {978-1-4503-5620-6},
	url = {https://dl.acm.org/doi/10.1145/3173574.3173577},
	doi = {10.1145/3173574.3173577},
	series = {{CHI} '18},
	abstract = {Many conversational agents ({CAs}) are developed to answer users' questions in a specialized domain. In everyday use of {CAs}, user experience may extend beyond satisfying information needs to the enjoyment of conversations with {CAs}, some of which represent playful interactions. By studying a field deployment of a Human Resource chatbot, we report on users' interest areas in conversational interactions to inform the development of {CAs}. Through the lens of statistical modeling, we also highlight rich signals in conversational interactions for inferring user satisfaction with the instrumental usage and playful interactions with the agent. These signals can be utilized to develop agents that adapt functionality and interaction styles. By contrasting these signals, we shed light on the varying functions of conversational interactions. We discuss design implications for {CAs}, and directions for developing adaptive agents based on users' conversational behaviors.},
	pages = {1--13},
	booktitle = {Proceedings of the 2018 {CHI} Conference on Human Factors in Computing Systems},
	publisher = {Association for Computing Machinery},
	author = {Liao, Q. Vera and Mas-ud Hussain, Muhammed and Chandar, Praveen and Davis, Matthew and Khazaeni, Yasaman and Crasso, Marco Patricio and Wang, Dakuo and Muller, Michael and Shami, N. Sadat and Geyer, Werner},
	urldate = {2024-11-11},
	date = {2018-04-19},
	keywords = {refs},
	file = {Full Text PDF:C\:\\Users\\Lewis\\Zotero\\storage\\P7UK3GZB\\Liao et al. - 2018 - All Work and No Play.pdf:application/pdf},
}


@inproceedings{liao_all_2018,
	location = {New York, {NY}, {USA}},
	title = {All Work and No Play?},
	isbn = {978-1-4503-5620-6},
	url = {https://dl.acm.org/doi/10.1145/3173574.3173577},
	doi = {10.1145/3173574.3173577},
	series = {{CHI} '18},
	abstract = {Many conversational agents ({CAs}) are developed to answer users' questions in a specialized domain. In everyday use of {CAs}, user experience may extend beyond satisfying information needs to the enjoyment of conversations with {CAs}, some of which represent playful interactions. By studying a field deployment of a Human Resource chatbot, we report on users' interest areas in conversational interactions to inform the development of {CAs}. Through the lens of statistical modeling, we also highlight rich signals in conversational interactions for inferring user satisfaction with the instrumental usage and playful interactions with the agent. These signals can be utilized to develop agents that adapt functionality and interaction styles. By contrasting these signals, we shed light on the varying functions of conversational interactions. We discuss design implications for {CAs}, and directions for developing adaptive agents based on users' conversational behaviors.},
	pages = {1--13},
	booktitle = {Proceedings of the 2018 {CHI} Conference on Human Factors in Computing Systems},
	publisher = {Association for Computing Machinery},
	author = {Liao, Q. Vera and Mas-ud Hussain, Muhammed and Chandar, Praveen and Davis, Matthew and Khazaeni, Yasaman and Crasso, Marco Patricio and Wang, Dakuo and Muller, Michael and Shami, N. Sadat and Geyer, Werner},
	urldate = {2024-11-11},
	date = {2018-04-19},
	keywords = {refs},
	file = {Full Text PDF:C\:\\Users\\Lewis\\Zotero\\storage\\P7UK3GZB\\Liao et al. - 2018 - All Work and No Play.pdf:application/pdf},
}


@article{weizenbaum_elizacomputer_1966,
	title = {{ELIZA}—a computer program for the study of natural language communication between man and machine},
	volume = {9},
	issn = {0001-0782},
	url = {https://dl.acm.org/doi/10.1145/365153.365168},
	doi = {10.1145/365153.365168},
	pages = {36--45},
	number = {1},
	journaltitle = {Commun. {ACM}},
	author = {Weizenbaum, Joseph},
	urldate = {2024-11-19},
	date = {1966-01-01},
	keywords = {refs},
	file = {Full Text PDF:C\:\\Users\\Lewis\\Zotero\\storage\\GL53T9CT\\Weizenbaum - 1966 - ELIZA—a computer program for the study of natural language communication between man and machine.pdf:application/pdf},
}

@article{kuhail_interacting_2023,
	title = {Interacting with educational chatbots: A systematic review},
	volume = {28},
	doi = {10.1007/s10639-022-11177-3},
	shorttitle = {Interacting with educational chatbots},
	abstract = {Chatbots hold the promise of revolutionizing education by engaging learners, personalizing learning activities, supporting educators, and developing deep insight into learners’ behavior. However, there is a lack of studies that analyze the recent evidence-based chatbot-learner interaction design techniques applied in education. This study presents a systematic review of 36 papers to understand, compare, and reflect on recent attempts to utilize chatbots in education using seven dimensions: educational field, platform, design principles, the role of chatbots, interaction styles, evidence, and limitations. The results show that the chatbots were mainly designed on a web platform to teach computer science, language, general education, and a few other fields such as engineering and mathematics. Further, more than half of the chatbots were used as teaching agents, while more than a third were peer agents. Most of the chatbots used a predetermined conversational path, and more than a quarter utilized a personalized learning approach that catered to students’ learning needs, while other chatbots used experiential and collaborative learning besides other design principles. Moreover, more than a third of the chatbots were evaluated with experiments, and the results primarily point to improved learning and subjective satisfaction. Challenges and limitations include inadequate or insufficient dataset training and a lack of reliance on usability heuristics. Future studies should explore the effect of chatbot personality and localization on subjective satisfaction and learning effectiveness. © 2022, The Author(s).},
	pages = {973--1018},
	number = {1},
	journaltitle = {Education and Information Technologies},
	author = {Kuhail, M.A. and Alturki, N. and Alramlawi, S. and Alhejori, K.},
	date = {2023},
	keywords = {refs, Chatbot, Conversational Agent, Educational Bot, Human-Computer Interaction, Interaction Styles, Literature Review},
	file = {Full Text:C\:\\Users\\Lewis\\Zotero\\storage\\IJEULRF4\\Kuhail et al. - 2023 - Interacting with educational chatbots A systematic review.pdf:application/pdf;Snapshot:C\:\\Users\\Lewis\\Zotero\\storage\\NBJ6SYA4\\display.html:text/html},
}


@article{neumann_llm-driven_2024,
	title = {An {LLM}-Driven Chatbot in Higher Education for Databases and Information Systems},
	issn = {1557-9638},
	url = {https://ieeexplore.ieee.org/abstract/document/10706931},
	doi = {10.1109/TE.2024.3467912},
	abstract = {Contribution: This research explores the benefits and challenges of developing, deploying, and evaluating a large language models ({LLMs}) chatbot, {MoodleBot}, in computer science classroom settings. It highlights the potential of integrating {LLMs} into {LMSs} like Moodle to support self-regulated learning ({SRL}) and help-seeking behavior. Background: Computer science educators face immense challenges incorporating novel tools into {LMSs} to create a supportive and engaging learning environment. {MoodleBot} addresses this challenge by offering an interactive platform for both students and teachers. Research Questions: Despite issues like bias, hallucinations, and teachers’ and educators’ resistance to embracing new ({AI}) technologies, this research investigates two questions: ({RQ}1) To what extent do students accept {MoodleBot} as a valuable tool for learning support? ({RQ}2) How accurately does {MoodleBot} churn out responses, and how congruent are these with the established course content? Methodology: This study reviews pedagogical literature on {AI}-driven chatbots and adopts the retrieval-augmented generation ({RAG}) approach for {MoodleBot}’s design and data processing. The technology acceptance model ({TAM}) evaluates user acceptance through constructs like perceived usefulness ({PU}) and Ease of Use. Forty-six students participated, with 30 completing the {TAM} questionnaire. Findings: {LLM}-based chatbots like {MoodleBot} can significantly improve the teaching and learning process. This study revealed a high accuracy rate (88\%) in providing course-related assistance. Positive responses from students attest to the efficacy and applicability of {AI}-driven educational tools. These findings indicate that educational chatbots are suitable for integration into courses to improve personalized learning and reduce teacher administrative burden, although improvements in automated fact-checking are needed.},
	pages = {1--14},
	journaltitle = {{IEEE} Transactions on Education},
	author = {Neumann, Alexander Tobias and Yin, Yue and Sowe, Sulayman and Decker, Stefan and Jarke, Matthias},
	urldate = {2024-11-19},
	date = {2024},
	note = {Conference Name: {IEEE} Transactions on Education},
	keywords = {refs, Accuracy, Adaptation models, Chatbots, Computer science, Databases, Education, higher education, Information systems, Information technology, large language model ({LLM}), Mentoring, moodle, moodlebot, Vectors},
	file = {Full Text PDF:C\:\\Users\\Lewis\\Zotero\\storage\\DR7KZW2Z\\Neumann et al. - 2024 - An LLM-Driven Chatbot in Higher Education for Databases and Information Systems.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\Lewis\\Zotero\\storage\\Z4W8B9B9\\10706931.html:text/html},
}


@inproceedings{shuster_retrieval_2021,
	location = {Punta Cana, Dominican Republic},
	title = {Retrieval Augmentation Reduces Hallucination in Conversation},
	url = {https://aclanthology.org/2021.findings-emnlp.320},
	doi = {10.18653/v1/2021.findings-emnlp.320},
	abstract = {Despite showing increasingly human-like conversational abilities, state-of-the-art dialogue models often suffer from factual incorrectness and hallucination of knowledge (Roller et al., 2020). In this work we explore the use of neural-retrieval-in-the-loop architectures - recently shown to be effective in open-domain {QA} (Lewis et al., 2020b; Izacard and Grave, 2020) - for knowledge-grounded dialogue, a task that is arguably more challenging as it requires querying based on complex multi-turn dialogue context and generating conversationally coherent responses. We study various types of architectures with multiple components - retrievers, rankers, and encoder-decoders - with the goal of maximizing knowledgeability while retaining conversational ability. We demonstrate that our best models obtain state-of-the-art performance on two knowledge-grounded conversational tasks. The models exhibit open-domain conversational capabilities, generalize effectively to scenarios not within the training data, and, as verified by human evaluations, substantially reduce the well-known problem of knowledge hallucination in state-of-the-art chatbots.},
	eventtitle = {Findings 2021},
	pages = {3784--3803},
	booktitle = {Findings of the Association for Computational Linguistics: {EMNLP} 2021},
	publisher = {Association for Computational Linguistics},
	author = {Shuster, Kurt and Poff, Spencer and Chen, Moya and Kiela, Douwe and Weston, Jason},
	editor = {Moens, Marie-Francine and Huang, Xuanjing and Specia, Lucia and Yih, Scott Wen-tau},
	urldate = {2024-11-19},
	keywords = {refs},
	date = {2021-11},
	file = {Full Text PDF:C\:\\Users\\Lewis\\Zotero\\storage\\RNQY93EX\\Shuster et al. - 2021 - Retrieval Augmentation Reduces Hallucination in Conversation.pdf:application/pdf},
}


@article{ge_development_2023,
	title = {Development of a Liver Disease-Specific Large Language Model Chat Interface using Retrieval Augmented Generation},
	rights = {cc by-nc-nd},
	url = {https://europepmc.org/articles/PMC10659484},
	doi = {10.1101/2023.11.10.23298364},
	abstract = {{BackgroundLarge} language models ({LLMs}) have significant capabilities in clinical information processing tasks. Commercially available {LLMs}, however, are not optimized for clinical uses and are prone to generating incorrect or hallucinatory information. Retrieval-augmented generation ({RAG}) is an enterprise architecture that allows embedding of customized data into {LLMs}. This approach "specializes" the {LLMs} and is thought to reduce hallucinations.{MethodsWe} developed "{LiVersa}," a liver disease-specific {LLM}, by using our institution's protected health information ({PHI})-complaint text embedding and {LLM} platform, "Versa." We conducted {RAG} on 30 publicly available American Association for the Study of Liver Diseases ({AASLD}) guidelines and guidance documents to be incorporated into {LiVersa}. We evaluated {LiVersa}'s performance by comparing its responses versus those of trainees from a previously published knowledge assessment study regarding hepatitis B ({HBV}) treatment and hepatocellular carcinoma ({HCC}) surveillance.{ResultsLiVersa} answered all 10 questions correctly when forced to provide a "yes" or "no" answer. Full detailed responses with justifications and rationales, however, were not completely correct for three of the questions.{DiscussionsIn} this study, we demonstrated the ability to build disease-specific and {PHI}-compliant {LLMs} using {RAG}. While our {LLM}, {LiVersa}, demonstrated more specificity in answering questions related to clinical hepatology - there were some knowledge deficiencies due to limitations set by the number and types of documents used for {RAG}. The {LiVersa} prototype, however, is a proof of concept for utilizing {RAG} to customize {LLMs} for clinical uses and a potential strategy to realize personalized medicine in the future.},
	pages = {2023.11.10.23298364},
	journaltitle = {{medRxiv}},
	shortjournal = {{medRxiv}},
	author = {Ge, Jin and Sun, Steve and Owens, Joseph and Galvez, Victor and Gologorskaya, Oksana and Lai, Jennifer C and Pletcher, Mark J and Lai, Ki},
	urldate = {2024-11-19},
	date = {2023-11-01},
	pmid = {37986764},
	pmcid = {PMC10659484},
	keywords = {refs},
	file = {Full Text PDF (Open access):C\:\\Users\\Lewis\\Zotero\\storage\\XBU6VL2P\\Ge et al. - 2023 - Development of a Liver Disease-Specific Large Language Model Chat Interface using Retrieval Augmente.pdf:application/pdf},
}

@article{schobel_charting_2024,
	title = {Charting the Evolution and Future of Conversational Agents: A Research Agenda Along Five Waves and New Frontiers},
	volume = {26},
	issn = {1572-9419},
	url = {https://doi.org/10.1007/s10796-023-10375-9},
	doi = {10.1007/s10796-023-10375-9},
	shorttitle = {Charting the Evolution and Future of Conversational Agents},
	abstract = {Conversational agents ({CAs}) have come a long way from their first appearance in the 1960s to today’s generative models. Continuous technological advancements such as statistical computing and large language models allow for an increasingly natural and effortless interaction, as well as domain-agnostic deployment opportunities. Ultimately, this evolution begs multiple questions: How have technical capabilities developed? How is the nature of work changed through humans’ interaction with conversational agents? How has research framed dominant perceptions and depictions of such agents? And what is the path forward? To address these questions, we conducted a bibliometric study including over 5000 research articles on {CAs}. Based on a systematic analysis of keywords, topics, and author networks, we derive “five waves of {CA} research” that describe the past, present, and potential future of research on {CAs}. Our results highlight fundamental technical evolutions and theoretical paradigms in {CA} research. Therefore, we discuss the moderating role of big technologies, and novel technological advancements like {OpenAI} {GPT} or {BLOOM} {NLU} that mark the next frontier of {CA} research. We contribute to theory by laying out central research streams in {CA} research, and offer practical implications by highlighting the design and deployment opportunities of {CAs}.},
	pages = {729--754},
	number = {2},
	journaltitle = {Information Systems Frontiers},
	shortjournal = {Inf Syst Front},
	author = {Schöbel, Sofia and Schmitt, Anuschka and Benner, Dennis and Saqr, Mohammed and Janson, Andreas and Leimeister, Jan Marco},
	urldate = {2024-11-20},
	date = {2024-04-01},
	langid = {english},
	keywords = {refs, Artificial Intelligence, Bibliometric analysis, Chatbot, {ChatGPT}, Conversational agent, Generative artificial intelligence, Large language models, Voice assistant},
	file = {Full Text PDF:C\:\\Users\\Lewis\\Zotero\\storage\\H5U5Y9YT\\Schöbel et al. - 2024 - Charting the Evolution and Future of Conversational Agents A Research Agenda Along Five Waves and N.pdf:application/pdf},
}

@article{siriwardhana_improving_2023,
	title = {Improving the Domain Adaptation of Retrieval Augmented Generation ({RAG}) Models for Open Domain Question Answering},
	volume = {11},
	issn = {2307-387X},
	url = {https://doi.org/10.1162/tacl_a_00530},
	doi = {10.1162/tacl_a_00530},
	abstract = {Retrieval Augment Generation ({RAG}) is a recent advancement in Open-Domain Question Answering ({ODQA}). {RAG} has only been trained and explored with a Wikipedia-based external knowledge base and is not optimized for use in other specialized domains such as healthcare and news. In this paper, we evaluate the impact of joint training of the retriever and generator components of {RAG} for the task of domain adaptation in {ODQA}. We propose {RAG}-end2end, an extension to {RAG} that can adapt to a domain-specific knowledge base by updating all components of the external knowledge base during training. In addition, we introduce an auxiliary training signal to inject more domain-specific knowledge. This auxiliary signal forces {RAG}-end2end to reconstruct a given sentence by accessing the relevant information from the external knowledge base. Our novel contribution is that, unlike {RAG}, {RAG}-end2end does joint training of the retriever and generator for the end {QA} task and domain adaptation. We evaluate our approach with datasets from three domains: {COVID}-19, News, and Conversations, and achieve significant performance improvements compared to the original {RAG} model. Our work has been open-sourced through the {HuggingFace} Transformers library, attesting to our work’s credibility and technical consistency.},
	pages = {1--17},
	journaltitle = {Transactions of the Association for Computational Linguistics},
	shortjournal = {Transactions of the Association for Computational Linguistics},
	author = {Siriwardhana, Shamane and Weerasekera, Rivindu and Wen, Elliott and Kaluarachchi, Tharindu and Rana, Rajib and Nanayakkara, Suranga},
	urldate = {2024-11-23},
	date = {2023-01-12},
	keywords = {refs},
	file = {Full Text PDF:C\:\\Users\\Lewis\\Zotero\\storage\\NNQ7ATND\\Siriwardhana et al. - 2023 - Improving the Domain Adaptation of Retrieval Augmented Generation (RAG) Models for Open Domain Quest.pdf:application/pdf;Snapshot:C\:\\Users\\Lewis\\Zotero\\storage\\QJI4L9B7\\Improving-the-Domain-Adaptation-of-Retrieval.html:text/html},
}

@inproceedings{karpukhin_dense_2020,
	location = {Online},
	title = {Dense Passage Retrieval for Open-Domain Question Answering},
	url = {https://aclanthology.org/2020.emnlp-main.550},
	doi = {10.18653/v1/2020.emnlp-main.550},
	abstract = {Open-domain question answering relies on efficient passage retrieval to select candidate contexts, where traditional sparse vector space models, such as {TF}-{IDF} or {BM}25, are the de facto method. In this work, we show that retrieval can be practically implemented using dense representations alone, where embeddings are learned from a small number of questions and passages by a simple dual-encoder framework. When evaluated on a wide range of open-domain {QA} datasets, our dense retriever outperforms a strong Lucene-{BM}25 system greatly by 9\%-19\% absolute in terms of top-20 passage retrieval accuracy, and helps our end-to-end {QA} system establish new state-of-the-art on multiple open-domain {QA} benchmarks.},
	eventtitle = {{EMNLP} 2020},
	pages = {6769--6781},
	booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing ({EMNLP})},
	publisher = {Association for Computational Linguistics},
	author = {Karpukhin, Vladimir and Oguz, Barlas and Min, Sewon and Lewis, Patrick and Wu, Ledell and Edunov, Sergey and Chen, Danqi and Yih, Wen-tau},
	editor = {Webber, Bonnie and Cohn, Trevor and He, Yulan and Liu, Yang},
	urldate = {2024-11-23},
	date = {2020-11},
	keywords = {refs},
	file = {Full Text PDF:C\:\\Users\\Lewis\\Zotero\\storage\\R59JID5J\\Karpukhin et al. - 2020 - Dense Passage Retrieval for Open-Domain Question Answering.pdf:application/pdf},
}

@inproceedings{komeili_internet-augmented_2022,
	location = {Dublin, Ireland},
	title = {Internet-Augmented Dialogue Generation},
	url = {https://aclanthology.org/2022.acl-long.579},
	doi = {10.18653/v1/2022.acl-long.579},
	abstract = {The largest store of continually updating knowledge on our planet can be accessed via internet search. In this work we study giving access to this information to conversational agents. Large language models, even though they store an impressive amount of knowledge within their weights, are known to hallucinate facts when generating dialogue (Shuster et al., 2021); moreover, those facts are frozen in time at the point of model training. In contrast, we propose an approach that learns to generate an internet search query based on the context, and then conditions on the search results to finally generate a response, a method that can employ up-to-the-minute relevant information. We train and evaluate such models on a newly collected dataset of human-human conversations whereby one of the speakers is given access to internet search during knowledgedriven discussions in order to ground their responses. We find that search-query based access of the internet in conversation provides superior performance compared to existing approaches that either use no augmentation or {FAISS}-based retrieval (Lewis et al., 2020b).},
	eventtitle = {{ACL} 2022},
	pages = {8460--8478},
	booktitle = {Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
	publisher = {Association for Computational Linguistics},
	author = {Komeili, Mojtaba and Shuster, Kurt and Weston, Jason},
	editor = {Muresan, Smaranda and Nakov, Preslav and Villavicencio, Aline},
	urldate = {2024-11-23},
	date = {2022-05},
	keywords = {refs},
	file = {Full Text PDF:C\:\\Users\\Lewis\\Zotero\\storage\\TR9FBXJN\\Komeili et al. - 2022 - Internet-Augmented Dialogue Generation.pdf:application/pdf},
}

@misc{lewis_pre-training_2020,
	title = {Pre-training via Paraphrasing},
	url = {http://arxiv.org/abs/2006.15020},
	doi = {10.48550/arXiv.2006.15020},
	abstract = {We introduce {MARGE}, a pre-trained sequence-to-sequence model learned with an unsupervised multi-lingual multi-document paraphrasing objective. {MARGE} provides an alternative to the dominant masked language modeling paradigm, where we self-supervise the reconstruction of target text by retrieving a set of related texts (in many languages) and conditioning on them to maximize the likelihood of generating the original. We show it is possible to jointly learn to do retrieval and reconstruction, given only a random initialization. The objective noisily captures aspects of paraphrase, translation, multi-document summarization, and information retrieval, allowing for strong zero-shot performance on several tasks. For example, with no additional task-specific training we achieve {BLEU} scores of up to 35.8 for document translation. We further show that fine-tuning gives strong performance on a range of discriminative and generative tasks in many languages, making {MARGE} the most generally applicable pre-training method to date.},
	number = {{arXiv}:2006.15020},
	publisher = {{arXiv}},
	author = {Lewis, Mike and Ghazvininejad, Marjan and Ghosh, Gargi and Aghajanyan, Armen and Wang, Sida and Zettlemoyer, Luke},
	urldate = {2024-11-23},
	date = {2020-06-26},
	eprinttype = {arxiv},
	eprint = {2006.15020},
	keywords = {refs, Computer Science - Computation and Language, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Preprint PDF:C\:\\Users\\Lewis\\Zotero\\storage\\P8QNCPUD\\Lewis et al. - 2020 - Pre-training via Paraphrasing.pdf:application/pdf;Snapshot:C\:\\Users\\Lewis\\Zotero\\storage\\37MP6VQK\\2006.html:text/html},
}

@online{openai_retrieval_nodate,
	title = {Retrieval Augmented Generation ({RAG}) and Semantic Search for {GPTs} {\textbar} {OpenAI} Help Center},
	url = {https://help.openai.com/en/articles/8868588-retrieval-augmented-generation-rag-and-semantic-search-for-gpts},
	abstract = {Learn about {RAG} and how it is useful to {GPT} builders},
	author = {{OpenAI}},
	urldate = {2024-11-23},
	langid = {english},
	keywords = {refs},
	file = {Snapshot:C\:\\Users\\Lewis\\Zotero\\storage\\VYCNN7CI\\8868588-retrieval-augmented-generation-rag-and-semantic-search-for-gpts.html:text/html},
}

@misc{zhang_sirens_2023,
	title = {Siren's Song in the {AI} Ocean: A Survey on Hallucination in Large Language Models},
	url = {http://arxiv.org/abs/2309.01219},
	doi = {10.48550/arXiv.2309.01219},
	shorttitle = {Siren's Song in the {AI} Ocean},
	abstract = {While large language models ({LLMs}) have demonstrated remarkable capabilities across a range of downstream tasks, a significant concern revolves around their propensity to exhibit hallucinations: {LLMs} occasionally generate content that diverges from the user input, contradicts previously generated context, or misaligns with established world knowledge. This phenomenon poses a substantial challenge to the reliability of {LLMs} in real-world scenarios. In this paper, we survey recent efforts on the detection, explanation, and mitigation of hallucination, with an emphasis on the unique challenges posed by {LLMs}. We present taxonomies of the {LLM} hallucination phenomena and evaluation benchmarks, analyze existing approaches aiming at mitigating {LLM} hallucination, and discuss potential directions for future research.},
	number = {{arXiv}:2309.01219},
	publisher = {{arXiv}},
	author = {Zhang, Yue and Li, Yafu and Cui, Leyang and Cai, Deng and Liu, Lemao and Fu, Tingchen and Huang, Xinting and Zhao, Enbo and Zhang, Yu and Chen, Yulong and Wang, Longyue and Luu, Anh Tuan and Bi, Wei and Shi, Freda and Shi, Shuming},
	urldate = {2024-11-23},
	date = {2023-09-24},
	eprinttype = {arxiv},
	eprint = {2309.01219},
	keywords = {refs, Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computers and Society, Computer Science - Machine Learning},
	file = {Preprint PDF:C\:\\Users\\Lewis\\Zotero\\storage\\KQ84FAGL\\Zhang et al. - 2023 - Siren's Song in the AI Ocean A Survey on Hallucination in Large Language Models.pdf:application/pdf;Snapshot:C\:\\Users\\Lewis\\Zotero\\storage\\TC885PFJ\\2309.html:text/html},
}

@article{li_modernization_2023,
	title = {Modernization of Databases in the Cloud Era: Building Databases that Run Like Legos},
	volume = {16},
	issn = {2150-8097},
	url = {https://dl.acm.org/doi/10.14778/3611540.3611639},
	doi = {10.14778/3611540.3611639},
	shorttitle = {Modernization of Databases in the Cloud Era},
	abstract = {Utilizing cloud for common and critical computing infrastructures has already become the norm across the board. The rapid evolvement of the underlying cloud infrastructure and the revolutionary development of {AI} present both challenges and opportunities for building new database architectures and systems. It is crucial to modernize database systems in the cloud era, so that next generation cloud native databases may run like legos-they are adaptive, flexible, reliable, and smart towards dynamic workloads and varying requirements.That said, we observe four critical trends and requirements for the modernization of cloud databases: embracing cloud-native architecture, full integration with cloud platform and orchestration, co-design for data fabric, and moving towards being {AI} augmented. Modernizing database systems by adopting these critical trends and addressing key challenges associated with them provide ample opportunities for data management communities from both academia and industry to explore. We will provide an in-depth case study of how we modernize {PolarDB} with respect to embracing these four trends in the cloud era. Our ultimate goal is to build databases that run just like playing with legos, so that a database system fits for rich and dynamic workloads and requirements in a self-adaptive, performant, easy-/intuitive-to use, reliable, and intelligent manner.},
	pages = {4140--4151},
	number = {12},
	journaltitle = {Proc. {VLDB} Endow.},
	author = {Li, Feifei},
	urldate = {2024-11-23},
	date = {2023-08-01},
	keywords = {refs},
	file = {Full Text PDF:C\:\\Users\\Lewis\\Zotero\\storage\\W4G8NJQD\\Li - 2023 - Modernization of Databases in the Cloud Era Building Databases that Run Like Legos.pdf:application/pdf},
}

% Mildly uncomfortable about citing this one given just precisely how closely it relates to my project.
@inproceedings{odede_jaybot_2024,
	location = {New York, {NY}, {USA}},
	title = {{JayBot} -- Aiding University Students and Admission with an {LLM}-based Chatbot},
	isbn = {9798400704345},
	url = {https://dl.acm.org/doi/10.1145/3627508.3638293},
	doi = {10.1145/3627508.3638293},
	series = {{CHIIR} '24},
	abstract = {This demo paper presents {JayBot}, an {LLM}-based chatbot system aimed at enhancing the user experience of prospective and current students, faculty, and staff at a {UK} university. The objective of {JayBot} is to provide information to users on general enquiries regarding course modules, duration, fees, entry requirements, lecturers, internship, career paths, course employability and other related aspects. Leveraging the use cases of generative artificial intelligence ({AI}), the chatbot application was built using {OpenAI}’s advanced large language model ({GPT}-3.5 turbo); to tackle issues such as hallucination as well as focus and timeliness of results, an embedding transformer model has been combined with a vector database and vector search. Prompt engineering techniques were employed to enhance the chatbot’s response abilities. Preliminary user studies indicate {JayBot}’s effectiveness and efficiency. The demo will showcase {JayBot} in a university admission use case and discuss further application scenarios.},
	pages = {391--395},
	booktitle = {Proceedings of the 2024 Conference on Human Information Interaction and Retrieval},
	publisher = {Association for Computing Machinery},
	author = {Odede, Julius and Frommholz, Ingo},
	urldate = {2024-11-19},
	keywords = {refs},
	date = {2024-03-10},
	file = {Full Text PDF:C\:\\Users\\Lewis\\Zotero\\storage\\UK8VJRKV\\Odede and Frommholz - 2024 - JayBot -- Aiding University Students and Admission with an LLM-based Chatbot.pdf:application/pdf},
}

@inproceedings{wang_milvus_2021,
	location = {New York, {NY}, {USA}},
	title = {Milvus: A Purpose-Built Vector Data Management System},
	isbn = {978-1-4503-8343-1},
	url = {https://dl.acm.org/doi/10.1145/3448016.3457550},
	doi = {10.1145/3448016.3457550},
	series = {{SIGMOD} '21},
	shorttitle = {Milvus},
	abstract = {Recently, there has been a pressing need to manage high-dimensional vector data in data science and {AI} applications. This trend is fueled by the proliferation of unstructured data and machine learning ({ML}), where {ML} models usually transform unstructured data into feature vectors for data analytics, e.g., product recommendation. Existing systems and algorithms for managing vector data have two limitations: (1) They incur serious performance issue when handling large-scale and dynamic vector data; and (2) They provide limited functionalities that cannot meet the requirements of versatile applications.This paper presents Milvus, a purpose-built data management system to efficiently manage large-scale vector data. Milvus supports easy-to-use application interfaces (including {SDKs} and {RESTful} {APIs}); optimizes for the heterogeneous computing platform with modern {CPUs} and {GPUs}; enables advanced query processing beyond simple vector similarity search; handles dynamic data for fast updates while ensuring efficient query processing; and distributes data across multiple nodes to achieve scalability and availability. We first describe the design and implementation of Milvus. Then we demonstrate the real-world use cases supported by Milvus. In particular, we build a series of 10 applications (e.g., image/video search, chemical structure analysis, {COVID}-19 dataset search, personalized recommendation, biological multi-factor authentication, intelligent question answering) on top of Milvus. Finally, we experimentally evaluate Milvus with a wide range of systems including two open source systems (Vearch and Microsoft {SPTAG}) and three commercial systems. Experiments show that Milvus is up to two orders of magnitude faster than the competitors while providing more functionalities. Now Milvus is deployed by hundreds of organizations worldwide and it is also recognized as an incubation-stage project of the {LF} {AI} \&amp; Data Foundation. Milvus is open-sourced at https://github.com/milvus-io/milvus.},
	pages = {2614--2627},
	booktitle = {Proceedings of the 2021 International Conference on Management of Data},
	publisher = {Association for Computing Machinery},
	author = {Wang, Jianguo and Yi, Xiaomeng and Guo, Rentong and Jin, Hai and Xu, Peng and Li, Shengjun and Wang, Xiangyu and Guo, Xiangzhou and Li, Chengming and Xu, Xiaohai and Yu, Kun and Yuan, Yuxing and Zou, Yinghao and Long, Jiquan and Cai, Yudong and Li, Zhenxiang and Zhang, Zhifeng and Mo, Yihua and Gu, Jun and Jiang, Ruiyi and Wei, Yi and Xie, Charles},
	urldate = {2024-11-23},
	date = {2021-06-18},
	keywords = {refs},
	file = {Full Text PDF:C\:\\Users\\Lewis\\Zotero\\storage\\MLK5UAE6\\Wang et al. - 2021 - Milvus A Purpose-Built Vector Data Management System.pdf:application/pdf},
}

@inproceedings{xie_brief_2023,
	title = {A Brief Survey of Vector Databases},
	url = {https://ieeexplore.ieee.org/document/10429609},
	doi = {10.1109/BigDIA60676.2023.10429609},
	abstract = {The explosive growth of massive high-dimensional data requires capabilities for data processing, storing, and analyzing. This brings significant challenges to traditional databases due to the poor ability to handle high-dimensional data and its original design for stand-alone machines. Fortunately, vector databases have provided a practical solution for the management and analysis of high-dimensional data. Especially, they retrieve results related to the query efficiently after encoding various forms of data (e.g., text, image, and video) into vectors. The purpose of this paper is to offer insight into vector databases by presenting a brief survey. Firstly, the workflow of vector databases including indexing and querying, is detailed along with a specific case. Subsequently, we elaborate on the related methods applied in vector databases, which are the core techniques to enhance search efficiency and reduce computational overhead, particularly similarity search algorithms and similarity metrics. Further, we introduce widely used vector database products (e.g., Pinecone, Chroma, and Milvus) and compare them from multiple factors that should be taken into consideration. We also discuss potential avenues for future research in this domain. To conclude, this survey provides a comprehensive understanding of vector databases for retrieval from vast high-dimensional datasets.},
	eventtitle = {2023 9th International Conference on Big Data and Information Analytics ({BigDIA})},
	pages = {364--371},
	booktitle = {2023 9th International Conference on Big Data and Information Analytics ({BigDIA})},
	author = {Xie, Xingrui and Liu, Han and Hou, Wenzhe and Huang, Hongbin},
	urldate = {2024-11-23},
	date = {2023-12},
	note = {{ISSN}: 2771-6902},
	keywords = {refs, Computational efficiency, Databases, high-dimensional data, Indexing, Measurement, nearest neighbors’ search, Reliability, similarity metrics, similarity search, Support vector machines, Surveys, vector databases},
}

@article{singer_development_2024,
	title = {Development and Evaluation of Aeyeconsult: A Novel Ophthalmology Chatbot Leveraging Verified Textbook Knowledge and {GPT}-4},
	volume = {81},
	issn = {1931-7204},
	url = {https://www.sciencedirect.com/science/article/pii/S1931720423004324},
	doi = {10.1016/j.jsurg.2023.11.019},
	shorttitle = {Development and Evaluation of Aeyeconsult},
	pages = {438--443},
	number = {3},
	journaltitle = {Journal of Surgical Education},
	shortjournal = {Journal of Surgical Education},
	author = {Singer, Maxwell B. and Fu, Julia J. and Chow, Jessica and Teng, Christopher C.},
	urldate = {2024-11-24},
	date = {2024-03-01},
	keywords = {refs, artificial intelligence, chatbot, {ChatGPT}, large language models, {OKAPs}},
	file = {ScienceDirect Snapshot:C\:\\Users\\Lewis\\Zotero\\storage\\RH5IA8AS\\S1931720423004324.html:text/html},
}

@online{langchain_introduction_nodate,
	title = {Introduction {\textbar} {LangChain}},
	url = {https://python.langchain.com/docs/introduction/},
	abstract = {{LangChain} is a framework for developing applications powered by large language models ({LLMs}).},
	author = {{LangChain}},
	urldate = {2024-11-24},
	langid = {english},
	keywords = {refs},
	file = {Snapshot:C\:\\Users\\Lewis\\Zotero\\storage\\HAPXIF98\\introduction.html:text/html},
}

@inproceedings{srivastava_desirable_2020,
	title = {Desirable Features of a Chatbot-building Platform},
	url = {https://ieeexplore.ieee.org/document/9230397},
	doi = {10.1109/HCCAI49649.2020.00016},
	abstract = {There is a visible eagerness in the business community to integrate chatbots with their websites and mobile apps. They provide a humanised interface to information and can serve as digital assistants that can perform tasks on behalf of an individual. There are many commercial platforms which provide interfaces to build these chatbots. They are used by both professional software developers as well as people from non-{IT} backgrounds. Based on our experiences with three popular chatbot-building platforms - Google Dialogflow, {IBM} Watson Assistant and Amazon Lex, we present a list of desirable features that these platforms should exhibit in order to cater to their mixed user base. We also rate the availability and ease of use of these features on the current versions of these platforms.},
	eventtitle = {2020 {IEEE} International Conference on Humanized Computing and Communication with Artificial Intelligence ({HCCAI})},
	pages = {61--64},
	booktitle = {2020 {IEEE} International Conference on Humanized Computing and Communication with Artificial Intelligence ({HCCAI})},
	author = {Srivastava, Saurabh and Prabhakar, T.V.},
	urldate = {2024-11-24},
	date = {2020-09},
	keywords = {refs, Business, Chatbot, chatbots, chatbot platforms, desired features, Conferences, Internet, Mobile applications, Software, Task analysis},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Lewis\\Zotero\\storage\\ASW2QCZ2\\9230397.html:text/html},
}

@online{ibm_ibm_2024,
	title = {{IBM} watsonx Assistant Virtual Agent},
	url = {https://www.ibm.com/products/watsonx-assistant},
	abstract = {{IBM} watsonx Assistant provides customers with fast, consistent and accurate answers across any application, device or channel.},
	author = {{IBM}},
	urldate = {2024-11-24},
	date = {2024-04-03},
	langid = {english},
	keywords = {refs}
}


@online{google_conversational_nodate,
	title = {Conversational Agents and Dialogflow},
	url = {https://cloud.google.com/products/conversational-agents},
	abstract = {Conversational Agents is a comprehensive platform for developing chatbots, voice bots, and virtual agents using natural language understanding and Google {AI}.},
	titleaddon = {Google Cloud},
	author = {{Google}},
	urldate = {2024-11-24},
	langid = {american},
	keywords = {refs},
	file = {Snapshot:C\:\\Users\\Lewis\\Zotero\\storage\\PEVD5AZW\\conversational-agents.html:text/html},
}

@online{microsoft_microsoft_nodate,
	title = {Microsoft Bot Framework},
	url = {https://dev.botframework.com/},
	author = {{Microsoft}},
	urldate = {2024-11-24},
	keywords = {refs},
	file = {Microsoft Bot Framework:C\:\\Users\\Lewis\\Zotero\\storage\\5SPGW9V7\\dev.botframework.com.html:text/html},
}

@article{vrontis_artificial_2022,
	title = {Artificial intelligence, robotics, advanced technologies and human resource management: a systematic review},
	volume = {33},
	issn = {0958-5192},
	url = {https://doi.org/10.1080/09585192.2020.1871398},
	doi = {10.1080/09585192.2020.1871398},
	shorttitle = {Artificial intelligence, robotics, advanced technologies and human resource management},
	abstract = {Although academic production in intelligent automation (e.g. artificial intelligence, robotics) has grown rapidly, we still lack a comprehensive understanding of the impacts of the utilization of these technologies in human resource management ({HRM}) at an organizational (firms) and individual (employees) level. This study therefore aims to systematize the academic inputs on intelligent automation so far and to clarify what are its main contributions to and challenges for {HRM}. In a systematic search of 13,136 potentially relevant studies published in the top {HRM}, international business ({IB}), general management ({GM}) and information management ({IM}) journals, we found 45 articles studying artificial intelligence, robotics and other advanced technologies within {HRM} settings. Results show that intelligent automation technologies constitute a new approach to managing employees and enhancing firm performance, thus offering several opportunities for {HRM} but also considerable challenges at a technological and ethical level. The impact of these technologies has been identified to concentrate on {HRM} strategies, namely, job replacement, human-robot/{AI} collaboration, decision-making and learning opportunities, and {HRM} activities, namely, recruiting, training and job performance. This study discusses these shifts in detail, along with the main contributions to theory and practice and directions for future research.},
	pages = {1237--1266},
	number = {6},
	journaltitle = {The International Journal of Human Resource Management},
	author = {Vrontis, Demetris and Christofi, Michael and Pereira, Vijay and Tarba, Shlomo and Makrides, Anna and Trichina, Eleni},
	urldate = {2024-11-24},
	date = {2022-03-26},
	note = {Publisher: Routledge},
	keywords = {refs, advanced technologies, artificial intelligence, human resource management, Intelligent automation, international business, robotics, systematic review},
	file = {Full Text PDF:C\:\\Users\\Lewis\\Zotero\\storage\\94JY82U8\\Vrontis et al. - 2022 - Artificial intelligence, robotics, advanced technologies and human resource management a systematic.pdf:application/pdf},
}

@online{pinecone_pinecone_nodate,
	title = {Pinecone Documentation},
	url = {https://docs.pinecone.io/guides/get-started/overview},
	titleaddon = {Pinecone Docs},
	author = {{Pinecone}},
	urldate = {2024-11-24},
	langid = {english},
	keywords = {refs},
	file = {Snapshot:C\:\\Users\\Lewis\\Zotero\\storage\\WEITI4EA\\overview.html:text/html},
}

@online{chroma_chroma_nodate,
	title = {Chroma},
	url = {https://www.trychroma.com/},
	abstract = {Chroma is the open-source {AI} application database. Batteries included.},
	author = {{Chroma}},
	keywords = {refs},
	urldate = {2024-11-24},
}

@misc{wang_assessing_2023,
	title = {Assessing the Reliability of Large Language Model Knowledge},
	url = {http://arxiv.org/abs/2310.09820},
	doi = {10.48550/arXiv.2310.09820},
	abstract = {Large language models ({LLMs}) have been treated as knowledge bases due to their strong performance in knowledge probing tasks. {LLMs} are typically evaluated using accuracy, yet this metric does not capture the vulnerability of {LLMs} to hallucination-inducing factors like prompt and context variability. How do we evaluate the capabilities of {LLMs} to consistently produce factually correct answers? In this paper, we propose {MOdel} {kNowledge} {relIabiliTy} {scORe} ({MONITOR}), a novel metric designed to directly measure {LLMs}' factual reliability. {MONITOR} computes the distance between the probability distributions of a valid output and its counterparts produced by the same {LLM} probing the same fact using different styles of prompts and contexts.Experiments on a comprehensive range of 12 {LLMs} demonstrate the effectiveness of {MONITOR} in evaluating the factual reliability of {LLMs} while maintaining a low computational overhead. In addition, we release the {FKTC} (Factual Knowledge Test Corpus) test set, containing 210,158 prompts in total to foster research along this line (https://github.com/Vicky-Wil/{MONITOR}).},
	number = {{arXiv}:2310.09820},
	publisher = {{arXiv}},
	author = {Wang, Weixuan and Haddow, Barry and Birch, Alexandra and Peng, Wei},
	urldate = {2024-11-24},
	date = {2023-10-15},
	eprinttype = {arxiv},
	eprint = {2310.09820},
	keywords = {refs, Computer Science - Computation and Language},
	file = {Preprint PDF:C\:\\Users\\Lewis\\Zotero\\storage\\GSWAS2F7\\Wang et al. - 2023 - Assessing the Reliability of Large Language Model Knowledge.pdf:application/pdf;Snapshot:C\:\\Users\\Lewis\\Zotero\\storage\\UN7SI8QQ\\2310.html:text/html},
}

@inproceedings{ahmed_zeyad_advancements_2024,
	title = {Advancements in the Efficacy of Flan-T5 for Abstractive Text Summarization: A Multi-Dataset Evaluation Using {ROUGE} and {BERTScore}},
	url = {https://ieeexplore.ieee.org/document/10616418?denied=},
	doi = {10.1109/APCI61480.2024.10616418},
	shorttitle = {Advancements in the Efficacy of Flan-T5 for Abstractive Text Summarization},
	abstract = {This research ventured into the realm of abstractive text summarization, focusing on the amalgamation and efficacy of sophisticated {NLP} models, notably Flan-T5. We employed these cutting-edge models on a variety of datasets, such as {XSum}, {CNN}/{DailyMail}, Multi-News, Newsroom, and Gigaword, to gauge their summarization abilities. The models' performance was assessed using complex metrics like {ROUGE} and {BERTScore}. A remarkable discovery was the attainment of a {ROUGE}-L score of 0.5021 on the Gigaword dataset, underscoring the models' proficiency in producing coherent and contextually precise summaries. The outcomes were substantial, indicating a noticeable improvement in the quality, coherence, and contextual accuracy of the summaries generated by these models. This study concludes that the application of Flan-T5 signifies a considerable progression in the field of abstractive text summarization. Their capacity to effectively process and abridge extensive information is a reflection of their technological capability and constitutes a significant step forward in {NLP}, opening up new avenues for data processing and knowledge dissemination.},
	eventtitle = {2024 International Conference on Advancements in Power, Communication and Intelligent Systems ({APCI})},
	pages = {1--5},
	booktitle = {2024 International Conference on Advancements in Power, Communication and Intelligent Systems ({APCI})},
	author = {Ahmed Zeyad, Abdulrahman Mohsen and Biradar, Arun},
	urldate = {2024-11-24},
	date = {2024-06},
	keywords = {refs, Abstractive Text Summarization, Accuracy, {BERTScore}, {CNN}/{DailyMail} Dataset, Data models, Flan-T5, Gigaword Dataset, Measurement, Multi-News Dataset, Natural language processing, Newsroom Dataset, {ROUGE}, Technological innovation, Text summarization, Training data, {XSum} Dataset},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Lewis\\Zotero\\storage\\YHGSREUR\\10616418.html:text/html},
}

@misc{hada_are_2024,
	title = {Are Large Language Model-based Evaluators the Solution to Scaling Up Multilingual Evaluation?},
	url = {http://arxiv.org/abs/2309.07462},
	doi = {10.48550/arXiv.2309.07462},
	abstract = {Large Language Models ({LLMs}) excel in various Natural Language Processing ({NLP}) tasks, yet their evaluation, particularly in languages beyond the top \$20\$, remains inadequate due to existing benchmarks and metrics limitations. Employing {LLMs} as evaluators to rank or score other models' outputs emerges as a viable solution, addressing the constraints tied to human annotators and established benchmarks. In this study, we explore the potential of {LLM}-based evaluators, specifically {GPT}-4 in enhancing multilingual evaluation by calibrating them against \$20\$K human judgments across three text-generation tasks, five metrics, and eight languages. Our analysis reveals a bias in {GPT}4-based evaluators towards higher scores, underscoring the necessity of calibration with native speaker judgments, especially in low-resource and non-Latin script languages, to ensure accurate evaluation of {LLM} performance across diverse languages.},
	number = {{arXiv}:2309.07462},
	publisher = {{arXiv}},
	author = {Hada, Rishav and Gumma, Varun and Wynter, Adrian de and Diddee, Harshita and Ahmed, Mohamed and Choudhury, Monojit and Bali, Kalika and Sitaram, Sunayana},
	urldate = {2024-11-24},
	date = {2024-02-13},
	eprinttype = {arxiv},
	eprint = {2309.07462},
	keywords = {refs, Computer Science - Computation and Language},
	file = {Preprint PDF:C\:\\Users\\Lewis\\Zotero\\storage\\K3553EPI\\Hada et al. - 2024 - Are Large Language Model-based Evaluators the Solution to Scaling Up Multilingual Evaluation.pdf:application/pdf;Snapshot:C\:\\Users\\Lewis\\Zotero\\storage\\RWFHMYAN\\2309.html:text/html},
}

@inproceedings{zheng_judging_2023,
	title = {Judging {LLM}-as-a-Judge with {MT}-Bench and Chatbot Arena},
	url = {https://openreview.net/forum?id=uccHPGDlao},
	abstract = {Evaluating large language model ({LLM}) based chat assistants is challenging due to their broad capabilities and the inadequacy of existing benchmarks in measuring human preferences. To address this, we explore using strong {LLMs} as judges to evaluate these models on more open-ended questions. We examine the usage and limitations of {LLM}-as-a-judge, including position, verbosity, and self-enhancement biases, as well as limited reasoning ability, and propose solutions to mitigate some of them. We then verify the agreement between {LLM} judges and human preferences by introducing two benchmarks: {MT}-bench, a multi-turn question set; and Chatbot Arena, a crowdsourced battle platform. Our results reveal that strong {LLM} judges like {GPT}-4 can match both controlled and crowdsourced human preferences well, achieving over 80{\textbackslash}\% agreement, the same level of agreement between humans. Hence, {LLM}-as-a-judge is a scalable and explainable way to approximate human preferences, which are otherwise very expensive to obtain. Additionally, we show our benchmark and traditional benchmarks complement each other by evaluating several variants of {LLaMA} and Vicuna. The {MT}-bench questions, 3K expert votes, and 30K conversations with human preferences are publicly available at https://github.com/lm-sys/{FastChat}/tree/main/fastchat/llm\_judge.},
	eventtitle = {Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
	author = {Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and Zhang, Hao and Gonzalez, Joseph E. and Stoica, Ion},
	urldate = {2024-11-24},
	date = {2023-11-02},
	langid = {english},
	keywords = {refs},
	file = {Full Text PDF:C\:\\Users\\Lewis\\Zotero\\storage\\IQ2YG458\\Zheng et al. - 2023 - Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena.pdf:application/pdf},
}


@online{deepeval_introduction_2024,
	title = {Introduction {\textbar} {DeepEval} - The Open-Source {LLM} Evaluation Framework},
	url = {https://docs.confident-ai.com/docs/metrics-introduction},
	abstract = {Quick Summary},
	author = {{DeepEval}},
	urldate = {2024-11-24},
	date = {2024-11-22},
	langid = {english},
	keywords = {refs}
}

@misc{liu_g-eval_2023,
	title = {G-Eval: {NLG} Evaluation using {GPT}-4 with Better Human Alignment},
	url = {http://arxiv.org/abs/2303.16634},
	doi = {10.48550/arXiv.2303.16634},
	shorttitle = {G-Eval},
	abstract = {The quality of texts generated by natural language generation ({NLG}) systems is hard to measure automatically. Conventional reference-based metrics, such as {BLEU} and {ROUGE}, have been shown to have relatively low correlation with human judgments, especially for tasks that require creativity and diversity. Recent studies suggest using large language models ({LLMs}) as reference-free metrics for {NLG} evaluation, which have the benefit of being applicable to new tasks that lack human references. However, these {LLM}-based evaluators still have lower human correspondence than medium-size neural evaluators. In this work, we present G-Eval, a framework of using large language models with chain-of-thoughts ({CoT}) and a form-filling paradigm, to assess the quality of {NLG} outputs. We experiment with two generation tasks, text summarization and dialogue generation. We show that G-Eval with {GPT}-4 as the backbone model achieves a Spearman correlation of 0.514 with human on summarization task, outperforming all previous methods by a large margin. We also propose preliminary analysis on the behavior of {LLM}-based evaluators, and highlight the potential issue of {LLM}-based evaluators having a bias towards the {LLM}-generated texts. The code is at https://github.com/nlpyang/geval},
	number = {{arXiv}:2303.16634},
	publisher = {{arXiv}},
	author = {Liu, Yang and Iter, Dan and Xu, Yichong and Wang, Shuohang and Xu, Ruochen and Zhu, Chenguang},
	urldate = {2024-11-24},
	date = {2023-05-23},
	eprinttype = {arxiv},
	eprint = {2303.16634},
	keywords = {refs, Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	file = {Preprint PDF:C\:\\Users\\Lewis\\Zotero\\storage\\5RKQ7A2T\\Liu et al. - 2023 - G-Eval NLG Evaluation using GPT-4 with Better Human Alignment.pdf:application/pdf;Snapshot:C\:\\Users\\Lewis\\Zotero\\storage\\8HUFKZGE\\2303.html:text/html},
}

@misc{mikolov_efficient_2013,
	title = {Efficient Estimation of Word Representations in Vector Space},
	url = {http://arxiv.org/abs/1301.3781},
	doi = {10.48550/arXiv.1301.3781},
	abstract = {We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.},
	number = {{arXiv}:1301.3781},
	publisher = {{arXiv}},
	author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
	urldate = {2024-11-24},
	date = {2013-09-07},
	eprinttype = {arxiv},
	eprint = {1301.3781},
	keywords = {refs, Computer Science - Computation and Language},
	file = {Preprint PDF:C\:\\Users\\Lewis\\Zotero\\storage\\WHVVEKND\\Mikolov et al. - 2013 - Efficient Estimation of Word Representations in Vector Space.pdf:application/pdf;Snapshot:C\:\\Users\\Lewis\\Zotero\\storage\\TVPYAQS4\\1301.html:text/html},
}

@misc{le_distributed_2014,
	title = {Distributed Representations of Sentences and Documents},
	url = {http://arxiv.org/abs/1405.4053},
	doi = {10.48550/arXiv.1405.4053},
	abstract = {Many machine learning algorithms require the input to be represented as a fixed-length feature vector. When it comes to texts, one of the most common fixed-length features is bag-of-words. Despite their popularity, bag-of-words features have two major weaknesses: they lose the ordering of the words and they also ignore semantics of the words. For example, "powerful," "strong" and "Paris" are equally distant. In this paper, we propose Paragraph Vector, an unsupervised algorithm that learns fixed-length feature representations from variable-length pieces of texts, such as sentences, paragraphs, and documents. Our algorithm represents each document by a dense vector which is trained to predict words in the document. Its construction gives our algorithm the potential to overcome the weaknesses of bag-of-words models. Empirical results show that Paragraph Vectors outperform bag-of-words models as well as other techniques for text representations. Finally, we achieve new state-of-the-art results on several text classification and sentiment analysis tasks.},
	number = {{arXiv}:1405.4053},
	publisher = {{arXiv}},
	author = {Le, Quoc V. and Mikolov, Tomas},
	urldate = {2024-11-24},
	date = {2014-05-22},
	eprinttype = {arxiv},
	eprint = {1405.4053},
	keywords = {refs, Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {Preprint PDF:C\:\\Users\\Lewis\\Zotero\\storage\\RCK7HDG5\\Le and Mikolov - 2014 - Distributed Representations of Sentences and Documents.pdf:application/pdf;Snapshot:C\:\\Users\\Lewis\\Zotero\\storage\\IQTZV6BS\\1405.html:text/html},
}

@inproceedings{devlin_bert_2019,
	location = {Minneapolis, Minnesota},
	title = {{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding},
	url = {https://aclanthology.org/N19-1423},
	doi = {10.18653/v1/N19-1423},
	shorttitle = {{BERT}},
	abstract = {We introduce a new language representation model called {BERT}, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), {BERT} is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained {BERT} model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. {BERT} is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the {GLUE} score to 80.5 (7.7 point absolute improvement), {MultiNLI} accuracy to 86.7\% (4.6\% absolute improvement), {SQuAD} v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and {SQuAD} v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
	eventtitle = {{NAACL}-{HLT} 2019},
	pages = {4171--4186},
	booktitle = {Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
	publisher = {Association for Computational Linguistics},
	author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	editor = {Burstein, Jill and Doran, Christy and Solorio, Thamar},
	keywords = {refs},
	urldate = {2024-11-06},
	date = {2019-06},
	file = {Full Text PDF:C\:\\Users\\Lewis\\Zotero\\storage\\WS9KH7AM\\Devlin et al. - 2019 - BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.pdf:application/pdf},
}

@online{openai_vector_nodate,
	title = {Vector embeddings},
	url = {https://platform.openai.com/docs/guides/embeddings},
	abstract = {Explore developer resources, tutorials, {API} docs, and dynamic examples to get the most out of {OpenAI}'s platform.},
	titleaddon = {Vector embeddings},
	author = {{OpenAI}},
	urldate = {2024-11-24},
	langid = {english},
	keywords = {refs},
	file = {Snapshot:C\:\\Users\\Lewis\\Zotero\\storage\\GPKG2R9Y\\embeddings.html:text/html},
}

@online{openai_introducing_nodate,
	title = {Introducing text and code embeddings},
	url = {https://openai.com/index/introducing-text-and-code-embeddings/},
	abstract = {We are introducing embeddings, a new endpoint in the {OpenAI} {API} that makes it easy to perform natural language and code tasks like semantic search, clustering, topic modeling, and classification.},
	author = {{OpenAI}},
	urldate = {2024-11-25},
	langid = {american},
	keywords = {refs},
	file = {Snapshot:C\:\\Users\\Lewis\\Zotero\\storage\\PHQXX9CD\\introducing-text-and-code-embeddings.html:text/html},
}

















% ===================================================================================================================
% BIBLIOGRAPHY FROM HERE
@online{IBMAIDef,
    author = {IBM},
    title = {What is AI?},
    date = {2024-08-16},
    url = {https://www.ibm.com/topics/artificial-intelligence},
    urldate = {2024-10-28},
    keywords = {bib}
}

@online{ICOAIDef,
    author = {ICO},
    title = {Definitions},
    url = {https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/artificial-intelligence/explaining-decisions-made-with-artificial-intelligence/part-1-the-basics-of-explaining-ai/definitions/},
    urldate = {2024-10-28},
    keywords = {bib}
}

@online{IBMChatbotDef,
    author = {IBM},
    title = {What is a chatbot?},
    url = {https://www.ibm.com/topics/chatbots},
    urldate = {2024-10-28},
    keywords = {bib}
}

@online{IBMGenAI,
    author = {IBM},
    title = {What is generative AI?},
    url = {https://research.ibm.com/blog/what-is-generative-AI},
    urldate = {2024-10-28},
    keywords = {bib}
}

@online{MITGenAI,
    author = {MIT},
    title = {Explained: Generative AI},
    date = {2023-11-09},
    url = {https://news.mit.edu/2023/explained-generative-ai-1109},
    urldate = {2024-10-28},
    keywords = {bib}
}

@online{CloudflareLLM,
    author = {Cloudflare},
    title = {What is a large language model (LLM)?},
    url = {https://www.cloudflare.com/en-gb/learning/ai/what-is-large-language-model/},
    urldate = {2024-10-28},
    keywords = {bib}
}

@online{UXDict,
    author = {{Cambridge Dictionary}},
    title = {Meaning of user experience in English},
    url = {https://dictionary.cambridge.org/dictionary/english/user-experience},
    urldate = {2024-10-28},
    keywords = {bib}
}

@online{IBMNLP,
	title = {What Is {NLP} (Natural Language Processing)? {\textbar} {IBM}},
	url = {https://www.ibm.com/topics/natural-language-processing},
	shorttitle = {What Is {NLP} (Natural Language Processing)?},
	abstract = {Natural language processing ({NLP}) is a subfield of artificial intelligence ({AI}) that uses machine learning to help computers communicate with human language.},
	author = {{IBM}},
	urldate = {2024-11-04},
	date = {2024-08-11},
	keywords = {bib}
}

@online{aws_what_nodate,
	title = {What is {RAG}? - Retrieval-Augmented Generation {AI} Explained - {AWS}},
	url = {https://aws.amazon.com/what-is/retrieval-augmented-generation/},
	shorttitle = {What is {RAG}?},
	abstract = {What is Retrieval-Augmented Generation ({RAG}), how and why businesses use {RAG} {AI}, and how to use {RAG} with {AWS}.},
	titleaddon = {Amazon Web Services, Inc.},
	author = {{AWS}},
	urldate = {2024-11-23},
	langid = {american},
	keywords = {bib},
	file = {Snapshot:C\:\\Users\\Lewis\\Zotero\\storage\\YQ5NLX8M\\retrieval-augmented-generation.html:text/html},
}

@online{databricks_retrieval_2023,
	title = {Retrieval Augmented Generation},
	url = {https://www.databricks.com/glossary/retrieval-augmented-generation-rag},
	abstract = {Retrieval augmented generation or {RAG} is an architectural approach that pulls your data as context for large language models ({LLMs}) to improve relevancy.},
	titleaddon = {Databricks},
	author = {{Databricks}},
	urldate = {2024-11-23},
	date = {2023-10-18},
	langid = {american},
	keywords = {bib},
	file = {Snapshot:C\:\\Users\\Lewis\\Zotero\\storage\\2XGJL6B4\\retrieval-augmented-generation-rag.html:text/html},
}

@online{elastic_what_nodate,
	title = {What is Semantic Search? {\textbar} A Comprehensive Semantic Search Guide},
	url = {https://www.elastic.co/what-is/semantic-search},
	shorttitle = {What is Semantic Search?},
	abstract = {Define semantic search and learn how it works. See how it differs from keyword search, its benefits, and how to get started using semantic search.},
	author = {{Elastic}},
	urldate = {2024-11-24},
	langid = {english},
	keywords = {bib},
	file = {Snapshot:C\:\\Users\\Lewis\\Zotero\\storage\\43FME4DW\\semantic-search.html:text/html},
}

@online{confident_ai_llm_nodate,
	title = {{LLM} Evaluation Metrics: The Ultimate {LLM} Evaluation Guide - Confident {AI}},
	url = {https://www.confident-ai.com/blog/llm-evaluation-metrics-everything-you-need-for-llm-evaluation},
	shorttitle = {{LLM} Evaluation Metrics},
	abstract = {In this article, I'll walkthrough everything you need to know about {LLM} evaluation metrics, with code samples.},
	author = {{Confident AI}},
	urldate = {2024-11-24},
	keywords = {bib},
	file = {Snapshot:C\:\\Users\\Lewis\\Zotero\\storage\\97Y6UPJ8\\llm-evaluation-metrics-everything-you-need-for-llm-evaluation.html:text/html},
}

@online{johnsonBillionscaleSimilaritySearch2017,
  title = {Billion-Scale Similarity Search with {{GPUs}}},
  author = {Johnson, Jeff and Douze, Matthijs and Jégou, Hervé},
  date = {2017-02-28},
  eprint = {1702.08734},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1702.08734},
  url = {http://arxiv.org/abs/1702.08734},
  urldate = {2025-03-10},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Data Structures and Algorithms,Computer Science - Databases,Computer Science - Information Retrieval},
  file = {C:\Users\Lewis\Zotero\storage\MKJZ3K5X\Johnson et al. - 2017 - Billion-scale similarity search with GPUs.pdf}
}

@online{metaFaissLibraryEfficient2017,
  title = {Faiss: {{A}} Library for Efficient Similarity Search},
  shorttitle = {Faiss},
  author = {{Meta}},
  date = {2017-03-29T16:00:00+00:00},
  url = {https://engineering.fb.com/2017/03/29/data-infrastructure/faiss-a-library-for-efficient-similarity-search/},
  urldate = {2025-03-10},
  langid = {american},
  organization = {Engineering at Meta},
  keywords = {refs},
  file = {C:\Users\Lewis\Zotero\storage\NVAWDFPD\faiss-a-library-for-efficient-similarity-search.html}
}

@article{wooCustomLargeLanguage2025,
  title = {Custom {{Large Language Models Improve Accuracy}}: {{Comparing Retrieval Augmented Generation}} and {{Artificial Intelligence Agents}} to {{Noncustom Models}} for {{Evidence-Based Medicine}}},
  shorttitle = {Custom {{Large Language Models Improve Accuracy}}},
  author = {Woo, J.J. and Yang, A.J. and Olsen, R.J. and Hasan, S.S. and Nawabi, D.H. and Nwachukwu, B.U. and Williams, III, R.J. and Ramkumar, P.N.},
  date = {2025},
  journaltitle = {Arthroscopy - Journal of Arthroscopic and Related Surgery},
  volume = {41},
  number = {3},
  pages = {565-573.e6},
  doi = {10.1016/j.arthro.2024.10.042},
  keywords = {refs},
  file = {C:\Users\Lewis\Zotero\storage\RHJNUHK9\display.html}
}

@article{tarsneyDeceptionManipulationGenerative2025,
  title = {Deception and Manipulation in Generative {{AI}}},
  author = {Tarsney, Christian},
  date = {2025-01-18},
  journaltitle = {Philosophical Studies},
  shortjournal = {Philos Stud},
  issn = {1573-0883},
  doi = {10.1007/s11098-024-02259-8},
  url = {https://doi.org/10.1007/s11098-024-02259-8},
  urldate = {2025-03-10},
  langid = {english},
 keywords = {refs},
  file = {C:\Users\Lewis\Zotero\storage\657GSCLZ\Tarsney - 2025 - Deception and manipulation in generative AI.pdf}
}

@online{weaviateWhatAgenticRAG2024,
  title = {What Is {{Agentic RAG}} | {{Weaviate}}},
  author = {{Weaviate}},
  date = {2024-11-05T00:00:00},
  url = {https://weaviate.io/blog/what-is-agentic-rag},
  urldate = {2025-03-10},
  langid = {english},
  keywords = {refs},
  file = {C:\Users\Lewis\Zotero\storage\ZMBQYDQK\what-is-agentic-rag.html}
}

@article{m.branAugmentingLargeLanguage2024,
  title = {Augmenting Large Language Models with Chemistry Tools},
  author = {M. Bran, A. and Cox, S. and Schilter, O. and Baldassari, C. and White, A.D. and Schwaller, P.},
  date = {2024},
  journaltitle = {Nature Machine Intelligence},
  volume = {6},
  number = {5},
  pages = {525--535},
  doi = {10.1038/s42256-024-00832-8},
  keywords = {refs},
  file = {C\:\\Users\\Lewis\\Zotero\\storage\\3YBQILYK\\M. Bran et al. - 2024 - Augmenting large language models with chemistry tools.pdf;C\:\\Users\\Lewis\\Zotero\\storage\\7MYFLBDG\\display.html}
}
